{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ba78d15",
   "metadata": {},
   "source": [
    "# Script para gestionar el procesadoo de la base de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645c0c97",
   "metadata": {},
   "source": [
    "El objetivo es crear un script capaz de gestionar los archivos csv que se coloquen en una carpeta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d79b73",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642d646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para gestionar el directorio\n",
    "import os\n",
    "import time\n",
    "\n",
    "#Para filtrar los datos\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65835817",
   "metadata": {},
   "source": [
    "## Definición de variables\n",
    "En este primer apartado se pueden definir algunas de las variables que condicionarán el resultado final del programa. Aquí lo que hace cada una de ellas:\n",
    "* En el inicio:\n",
    "    * Espera: Variable booleana para esperar tras la verificación del arbol de trabajo (para que se pueda ingresar los ficheros sin necesidad de reiniciar el programa) o si por el contrario no se quiere hacer la pausa (por motivos de fluidez).\n",
    "* En la parte de extracción de ficheros:\n",
    "    * Lista_exclusiones: Es una lista con los nombres de las carpetas que no se quieren añadir al procesado. Por ejemplo, si dentro de la lista está el nombre \"S7\" en el caso de encontrar una carpeta así llamada en alguno de los directorios su contenido no se procesará.\n",
    "    * max_directorios: Indica el número máximos de directorios que se deben de tener en cuenta. La principal función de dicha variable es dar una opción de escape a un bucle while. Si hay menos carpetas que las indicadas no pasa nada, pero si hay más llegado al nivel indicado el programa parará (y por lo tanto los ficheros que esten dentro de las carpetas más abajo no se procesarán).\n",
    "* En la parte de obtención de la matriz:\n",
    "    * junto_X: Variable booleana que especifica si quieres obtener las etiquetes (en caso de haberlas) en la misma matriz de salida o si las quieres en un fichero aparte.\n",
    "    * add_timestamp: Añade a la matriz de salida una columna extra con la etiqueta de tiempo de los datos originales.\n",
    "    * borrar_datos_nuevos: Variable booleana que indica si quieres borrar los datos referentes a AP's solo vistos en los datos de Testeo y/o Validación o si los quieres conservar (en caso afirmativo aparecerán al final de la lista de AP's base).\n",
    "    * inv_value: Valor al que se pondrán los puntos de accesos que no se hayan visto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b07b3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para el inicio\n",
    "Espera = False\n",
    "\n",
    "#Para la extracción de ficheros\n",
    "#Lista con los nombre de los directorios que se quieran excluir\n",
    "Lista_exclusiones=[\n",
    "    \"S7\"\n",
    "]\n",
    "\n",
    "#Número máximo de directorios que puede abrir antes de parar\n",
    "max_directorios = 5\n",
    "\n",
    "#Variable para indicar si se busca ordenar las lista de APs al crear la matriz o si se forman conforma vayan saliendo\n",
    "ordenar_listas=False #False= bucle for, True=np.uniques\n",
    "\n",
    "#Para la obtención de las matrices\n",
    "#Definimos si queremos las etiquetas en la misma matriz que los datos o por separado y si queremos borrar los datos que no aparezcan en la lista\n",
    "junto_Train = True\n",
    "junto_Test = True\n",
    "junto_Val = True\n",
    "\n",
    "#Para añadir la columna de tiempo a la matriz de salida\n",
    "add_timestamp = True\n",
    "\n",
    "#Definimos si queremos eliminar o conservar los datos que hagan referencia a AP's que solo se encuentren en los ficheros de validación y testeo\n",
    "borrar_datos_nuevos_Test = True\n",
    "borrar_datos_nuevos_Val = True\n",
    "\n",
    "#Variable para lanzar el checkeo del valor mínimo\n",
    "check_minimun = False\n",
    "\n",
    "#Valor por el que se reempplazarán las potencias que no se vean\n",
    "inv_value=-100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c775b7f0",
   "metadata": {},
   "source": [
    "## Creación del espacio de trabajo\n",
    "Esta parte del código se encargará de crear las diferentes carpetas en las que se almacenarán los datos procesados. Para ello lo primero que haremos en verificar si ya existe la configuración adecuada, y de no ser así se creará, indicando al usuario como ha de proceder.\n",
    "La idea es que el arbol de trabajo sea el siguiente:\n",
    "\n",
    "    |->Database\n",
    "        |->Raw_data\n",
    "            |->Train\n",
    "            |->Test\n",
    "            |->Val\n",
    "        |->Processed_data\n",
    "            |->Dia\n",
    "                |->Hora\n",
    "            \n",
    "En la carpeta \"Raw_data\" es donde irían los .csv que se van a procesar. Dentro de la misma hay varias opciones a la hora de procesar los datos:\n",
    "* Si se añaden csv en las carpetas \"Train\", \"Test\" y \"Val\" esos datos se usarán para dicho proceso.\n",
    "* Si se añaden listas que contengan \"listado\" en el nombre a alguna de las carpetas los datos de ese conjunto se procesaran siguiendo dicho listado.\n",
    "\n",
    "Finalmente los datos procesados se pueden recoger en la carpeta \"Processed_data\". Para evitar que se sobreescriban los datos se crea una carpeta cada vez que se lanza el programa, en la cual se indica el día (carpeta general) y la hora (subcarpeta en la que se guardan los datos procesados).\n",
    "\n",
    "En la carpeta de datos procesados siempre encontraras uno o varios archivos .csv (dependiendo de cuantos conjuntos vayas a crear y de si quieres las etiquetes juntas o separadas), junto con el listado de los AP's únicos que se ha usado para procesarlos y un .txt con información diversa del proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcdaead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para crear las carpetas a partir de una lista de direcciones\n",
    "def Crea_directorios(lista):\n",
    "  for direccion in lista:\n",
    "    os.mkdir(direccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b49ec653",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definimos todas las direcciones necesarias.\n",
    "current_path = os.getcwd()\n",
    "external_path = current_path + \"/Database\"\n",
    "\n",
    "raw_path = external_path + \"/Raw_data\"\n",
    "raw_train_path = raw_path + \"/Train\"\n",
    "raw_test_path = raw_path + \"/Test\"\n",
    "raw_val_path = raw_path + \"/Val\"\n",
    "\n",
    "#Y las direcciones de los archivos de salida\n",
    "processed_path = external_path + \"/Processed_data\"\n",
    "str_date = str(time.gmtime().tm_mday)+\"_\"+str(time.gmtime().tm_mon)+\"_\"+str(time.gmtime().tm_year)\n",
    "str_hour = str(time.gmtime().tm_hour)+\":\"+str(time.gmtime().tm_min)+\":\"+str(time.gmtime().tm_sec)\n",
    "date_path = processed_path + \"/\" + str_date\n",
    "hour_path = date_path + \"/\" + str_hour\n",
    "\n",
    "#Para la informacion\n",
    "str_info = (\"Información sobre el procesado de datos ejecutado el día \" + str(str_date) + \" a las \" +str(str_hour) +\".\\n\")\n",
    "\n",
    "lista_direcciones=[external_path,raw_path,raw_train_path,raw_test_path,raw_val_path,processed_path]\n",
    "\n",
    "#Primero comprobamos si existe la carpeta adecuada. \n",
    "if(os.path.exists(external_path)):\n",
    "    print(\"Encontrada la carpeta 'Database'. Procedemos a verificar que es la adecuada.\")\n",
    "    if(os.path.exists(raw_path) & os.path.exists(processed_path)):\n",
    "        if(os.path.exists(raw_train_path) & os.path.exists(raw_test_path) & os.path.exists(raw_val_path)):\n",
    "            print('\\033[1mCarpeta identificada con éxito.\\033[0m')\n",
    "        else:\n",
    "            print(\"Parece que hay un error. El arbol de trabajo es incorrecto, lo cual podría indicar que la carpeta 'Database' fue creada con otro fin. Procedo a cambiarla el nombre a 'Database_antigua' y creo un nuevo directorio con la configuración adecuada.\")\n",
    "            os.rename(external_path, external_path+'_antigua_' + str(time.time()))\n",
    "            Crea_directorios(lista_direcciones)\n",
    "            \n",
    "    else:\n",
    "        print(\"Parece que hay un error. El arbol de trabajo es incorrecto, lo cual podría indicar que la carpeta 'Database' fue creada con otro fin. Procedo a cambiarla el nombre a 'Database_antigua' y creo un nuevo directorio con la configuración adecuada.\")\n",
    "        os.rename(external_path, external_path+'_antigua_' + str(time.time()))\n",
    "        Crea_directorios(lista_direcciones)\n",
    "\n",
    "else:\n",
    "    print(\"No se ha encontrado la carpeta 'Database'. Se procede a crear todos los directorios.\")\n",
    "    Crea_directorios(lista_direcciones)    \n",
    "    print(\"El arbol de trabajo ya ha sido creado.\")\n",
    "    \n",
    "print(\"\\033[1m[info]\\033[0m: Por favor, diríjase a la dirección: '\"+ str(external_path) +\"' e ingrese los archivos .csv en la carpeta 'Raw_data' para continuar.\")\n",
    "print(\"Dentro de esa carpeta encontrará varias opciones, coloque los .csv en las carpetas de las que quiera crear un conjunto.\")\n",
    "print(\"Por ejemplo, si ingresa 2 archivos en la carpeta 'Train' ambos se procesaran como datos de entrenamiento, y si además mete otro dos en la carpeta 'Test' estos archivos se procesaran aparte en un conjunto de testeo.\")\n",
    "print(\"\\033[1m[info]\\033[0m: También puede meter un listado base con los AP's conforme los quieras colocar. Los datos se procesaran teniendo en cuenta esa lista.\")\n",
    "print(\"\\033[1m[importante]\\033[0m: Si quieres meter un listado en alguna carpeta asegurate de que este contenga el nombre 'listado'.\")\n",
    "print(\"\\033[1m[info]\\033[0m: Los archivos que queden fuera de alguna de estas carpetas no seran procesados.\")\n",
    "\n",
    "if(Espera):\n",
    "    #Creamos una espera por si no se han metido los datos\n",
    "    input(\"Cuando tengas todo listo pulsa el botón \\033[1m'Enter'\\033[0m y procederemos con el procesado de los datos.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e133a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empezamos a contar para saber cuanto tardamos en ejecutar el programa\n",
    "tiempo_inicio = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4a8b7a",
   "metadata": {},
   "source": [
    "## Obtención de los datos\n",
    "En esta parte del código  trabajaremos en los archivos .csv que se encuentren en la carpeta \"Raw_data\". La idea es que el código lea todos los archivos que encuentre y los procese, independientemente de la cantidad, por lo que el usuario es libre de meter cuantos archivos quiera."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2370203b",
   "metadata": {},
   "source": [
    "### Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3766b5",
   "metadata": {},
   "source": [
    "Primero comprobamos que haya algún dato a procesar en alguna de las carpetas, y de no ser así avisamos al usuario para que los meta. \n",
    "Dejamos listadas las ubicaciones para facilitar su procesado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18884d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para diferenciar los ficheros y carpetas de una lista de direcciones \n",
    "def Encuentra_ficheros(lista_direcciones):\n",
    "    #La función ha de generar una lista con las direcciones de los ficheros a apartir de una dirección de un nivel superior\n",
    "    Lista_ficheros = []\n",
    "    Lista_directorios = []\n",
    "\n",
    "    for direccion in lista_direcciones:\n",
    "        #print(direccion)\n",
    "    \n",
    "        if os.path.isdir(direccion): \n",
    "            Lista_directorios.append(direccion)\n",
    "            #print(\"Encontrado directorio.\")\n",
    "\n",
    "        else:\n",
    "            Lista_ficheros.append(direccion)\n",
    "    \n",
    "    return Lista_ficheros, Lista_directorios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44f3bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "Lista_raw_path=[\n",
    "    \"raw_train_path\",\n",
    "    \"raw_test_path\",\n",
    "    \"raw_val_path\"\n",
    "]\n",
    "\n",
    "str_info = str_info + \"\\n\\u25BA Registro de ficheros \\u25C4\\n\"\n",
    "\n",
    "#Recorremos la lista de direcciones \n",
    "for path in Lista_raw_path:\n",
    "    #Guardamos el nombre del conjunto (Train, Test, etc)\n",
    "    conjunto =  path[4].upper() + path[5:-5]\n",
    "    \n",
    "    #Si está vacio no hacemos nada, pero llevamos la cuenta para asegurar de que al menos una carpeta contenga algo\n",
    "    if(len(os.listdir(globals()[\"%s\" % path]))==0):\n",
    "        print(\"La carpeta '\\033[1m\"+str(conjunto)+\"\\033[0m' esta vacia.\")\n",
    "        \n",
    "    #Si tiene algo en su interior analizamos que clase de elemento es\n",
    "    else:\n",
    "        print(\"Se han encontrado los siguientes archivos en la carpeta '\\033[1m\"+str(conjunto)+\"\\033[0m':\")\n",
    "        str_info = str_info +\"Se han extraido datos de los siguientes archivos localizados en la carpeta \"+str(conjunto)+\":\\n\"\n",
    "        \n",
    "        #Inicializamos la matriz donde almacenaremos las direcciones de los archivos\n",
    "        globals()['direcciones_%s' % conjunto]=[]\n",
    "        \n",
    "        for elemento in os.listdir(globals()[\"%s\" % path]):\n",
    "            \n",
    "            #Nos aseguramos que el elemento no pertenezca a la lista de exclusiones\n",
    "            if(elemento not in Lista_exclusiones):\n",
    "                path_elemento = globals()[\"%s\" % path] + \"/\" + elemento\n",
    "\n",
    "                #Si el elemento es un fichero\n",
    "                if os.path.isdir(path_elemento)== False:\n",
    "                    globals()['direcciones_%s' % conjunto] += [path_elemento]\n",
    "\n",
    "                    print(\"\\t \\u23FADocumento: \" +str(elemento))\n",
    "                    str_info = str_info + \"\\t \\u23FADocumento: \" +str(elemento) +\"\\n\"\n",
    "\n",
    "                else:\n",
    "                    #Primero buscamos los ficheros desde el nivel superior\n",
    "                    Lista_superior = [path_elemento +\"/\" + files for files in os.listdir(path_elemento)]\n",
    "                    Lista_ficheros, Lista_directorios = Encuentra_ficheros(Lista_superior)\n",
    "                    #print(\"\\033[1mFicheros:\\033[0m \" + str(Lista_ficheros))\n",
    "                    #print(\"\\033[1mDirectorios:\\033[0m \" + str(Lista_directorios))\n",
    "\n",
    "                    print(\"\\t \\u23FACarpeta: \" +str(elemento) +\" formada por \"+str(len(Lista_ficheros))+\" ficheros y \"+str(len(Lista_directorios))+\" subcarpetas.\")\n",
    "                    str_info=str_info + \"\\t \\u23FACarpeta: \" +str(elemento) +\" formada por \"+str(len(Lista_ficheros))+\" ficheros y \"+str(len(Lista_directorios))+\" subcarpetas.\\n\"\n",
    "                    \n",
    "                    #En caso de encontrarnos con directorios en los niveles inferiores vamos bajando hasta sacar todos los ficheros\n",
    "                    contador = 0\n",
    "                    start_str = \"\\t \\u23FA\"\n",
    "                    str_sub=\"\"\n",
    "                    while((len(Lista_directorios)!=0) and (contador <= max_directorios)):\n",
    "                        \n",
    "                        #print(\"'\\033[1mEntrando en el bucle while'\\033[0m\")\n",
    "                        start_str = \"\\t\"+start_str\n",
    "                        str_sub = \"sub-\"+str_sub\n",
    "                        lis_direc=[]\n",
    "                        lis_fic=[]\n",
    "\n",
    "                        for direc in Lista_directorios:\n",
    "                            \n",
    "                            if(str(direc.split(\"/\")[-1]) not in Lista_exclusiones):\n",
    "                                print(start_str + \"Dentro de la carpeta \"+str(direc.split(\"/\")[-2])+\" se encuentra la \"+str_sub+\"carpeta \"+str(direc.split(\"/\")[-1])+\" que contenía \"+str(len(os.listdir(direc)))+\" elementos.\")\n",
    "                                str_info=str_info + start_str + \"Dentro de la carpeta \"+str(direc.split(\"/\")[-2])+\" se encuentra la \"+str_sub+\"carpeta \"+str(direc.split(\"/\")[-1])+\" que contenía \"+str(len(os.listdir(direc)))+\" elementos.\\n\"\n",
    "                                \n",
    "                                lis_direc+=[direc + \"/\" + str(fichero) for fichero in os.listdir(direc)]\n",
    "                            \n",
    "                            else:\n",
    "                                print(start_str +\"[Exclusión]: Dentro de la carpeta \"+str(direc.split(\"/\")[-2])+\" se encuentra la \"+str_sub+\"carpeta \"+str(direc.split(\"/\")[-1])+\" que pertenece a la lista de exclusión, por lo que no será procesada.\\n\")\n",
    "                                str_info=str_info + start_str + \"[Exclusión]: Dentro de la carpeta \"+str(direc.split(\"/\")[-2])+\" se encuentra la \"+str_sub+\"carpeta \"+str(direc.split(\"/\")[-1])+\" que pertenece a la lista de exclusión, por lo que no será procesada.\\n\"\n",
    "                        \n",
    "                        lis_fic, Lista_directorios = Encuentra_ficheros(lis_direc)\n",
    "                        if(len(lis_fic)!=0):\n",
    "                            Lista_ficheros = Lista_ficheros + lis_fic\n",
    "\n",
    "                        contador = contador +1\n",
    "\n",
    "                    globals()['direcciones_%s' % conjunto] += Lista_ficheros\n",
    "                    #print(\"\\t En total, dentro de \"+str(elemento)+\" se han localizado \"+str(len(Lista_ficheros))+\" archivos.\")\n",
    "                    #str_info=str_info+\"\\t En total, dentro de \"+str(elemento)+\" se han localizado \"+str(len(Lista_ficheros))+\" archivos.\\n\"\n",
    "\n",
    "                    #print(\"\\033[1mFicheros:\\033[0m \" + str(Lista_ficheros)+\"\\n\\033[1mTamaño:\\033[0m \"+str(len(Lista_ficheros)))\n",
    "                    #print(\"\\033[1mDirectorios:\\033[0m \" + str(Lista_directorios))\n",
    "                    \n",
    "            else:\n",
    "                print(\"\\t \\u23FAEl elemento \"+ str(element)+\" se encuentra dentro de la lista de exclusiones, por lo que no se procesará.\")\n",
    "                str_info=str_info +\"\\t \\u23FAEl elemento \"+ str(element)+\" se encuentra dentro de la lista de exclusiones, por lo que no se procesará.\\n\"\n",
    "           \n",
    "    if('direcciones_'+ str(conjunto) in globals()):\n",
    "        globals()['direcciones_%s' % conjunto] = sorted(globals()['direcciones_%s' % conjunto])\n",
    "    #print(\"\\033[1mFicheros \" +str(conjunto)+ \":\\033[0m \" + str(globals()['direcciones_%s' % conjunto]))\n",
    "    #print(\"\\033[1mDirectorios \" +str(conjunto)+ \":\\033[0m \" + str(Lista_directorios))\n",
    "    #print(\"\\n\")\n",
    "    \n",
    "assert ((\"direcciones_Train\" in globals()) or (\"direcciones_Test\" in globals()) or (\"direcciones_Val\" in globals())), \"[\\033[1mImportante\\033[0m]: No se ha encontrado ninguna archivo que procesar. Por favor, introduzca algún archivo y verifique que este no pertenezca a la lista de exclusiones.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4756ec",
   "metadata": {},
   "source": [
    "### Función para sacar las matrices\n",
    "\n",
    "Una vez tenemos listadas las direcciones de todos los archivos que vamos a procesar, creamos una función que tendrá como entrada ese listado y como salida una matriz con todos datos.\n",
    "La variable \"secuencia\" cuenta con las muestras que tiene cada fichero csv, de forma que acaba siendo una lista donde se guardan todas las secuencias que se han procesado.\n",
    "También en el caso de que exista un fichero \"listado\" en alguna de las carpetas lo procesará para que se puedan ordenar los datos conforme allí aparezcan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754a4304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Saca_matrices(direcciones):\n",
    "    #Almacenaremos los datos en una lista de listas de tamaño variable en función de la cantidad de ficheros que haya\n",
    "    datos_totales=[]\n",
    "    secuencias=[]\n",
    "    listado = None\n",
    "    orden=[]\n",
    "    \n",
    "    #Para cargar los datos usamos pd.read_csv(), el cual nos carga los datos en formato Dataframe, pero nosotros lo convertiremos a lista para poder trabajar con ello\n",
    "    for direccion in direcciones:\n",
    "        #Comprobamos que no sea un archivo de listado\n",
    "        if(\"listado\" in direccion):\n",
    "            listado = pd.read_csv(direccion, header = None).to_numpy()[1:]\n",
    "            listado = np.array([item for sublist in listado for item in sublist])\n",
    "            print(\"[Importante]: Se ha encontrado una lista base\")\n",
    "            globals()[\"str_info\"]=globals()[\"str_info\"] + \"[Importante]: Se ha encontrado una lista base\\n\"\n",
    "        else:\n",
    "            print(direccion)\n",
    "            datos_totales.append((pd.read_csv(direccion, on_bad_lines='skip', header = None)).to_numpy().tolist())\n",
    "    \n",
    "    #Mostramos la cantidad de datos que se han leido para asegurarnos más tarde de que no se pierda ninguno\n",
    "    print(\"En total se han descargado \"+ str(len(datos_totales)) +\" ficheros, los cuales se colocarán siguiendo el orden que se muestra a continuación:\")\n",
    "    globals()[\"str_info\"]=globals()[\"str_info\"] + \"En total se han descargado \"+ str(len(datos_totales)) +\" ficheros, los cuales tienen las siguientes dimensiones:\\n\"\n",
    "    \n",
    "    cuenta_datos = 0\n",
    "    for i in range(len(datos_totales)):\n",
    "        print(\"El archivo '\"+ str(direcciones[i]) +\" contenía \"+ str(len(datos_totales[i])) +\" datos.\")\n",
    "        print(\"En total representaban \"+str(datos_totales[i][-1][0])+\" secuencias.\")\n",
    "        globals()[\"str_info\"]=globals()[\"str_info\"] + \"\\t\\u23FA\" + \"El archivo '\"+ str(direcciones[i]) +\" contenía \"+ str(len(datos_totales[i])) +\" datos, los cuales en total representaban \"+str(datos_totales[i][-1][0] +1)+\" secuencias.\\n\"\n",
    "        cuenta_datos = cuenta_datos + len(datos_totales[i])\n",
    "        secuencias.append(datos_totales[i][-1][0])\n",
    "        orden.append([str(direcciones[i]), datos_totales[i][-1][0]])\n",
    "        \n",
    "    print(\"Por lo que el total de datos a procesar tiene que ser de \"+str(cuenta_datos))\n",
    "    \n",
    "    #Una vez cargados los datos los pasaremos de una lista de listas a una sola lista\n",
    "    flat_list = [item for sublist in datos_totales for item in sublist]\n",
    "    print(\"Al realizar el 'aplanamiento' nos quedamos con un total de \"+ str(len(flat_list)))\n",
    "    assert len(flat_list) == cuenta_datos, \"Ha surgido un error al aplanar los datos. Originalmente había \"+ str(cuenta_datos) +\", pero tras aplanar nos hemos quedado con \"+ str(len(flat_list)) +\".Por favor, revisa el código\"\n",
    "    \n",
    "    #Escribimos más informacion\n",
    "    globals()[\"str_info\"]=globals()[\"str_info\"] + \"El total de datos a procesar dentro de este conjunto ha de ser de \"+str(cuenta_datos)+ \" contenidos en \"+str(sum(secuencias)+len(secuencias))+\" secuencias.\\n\"\n",
    "    \n",
    "    #Finalmente convertimos dicha lista a formato matriz para poder trabajar con ella de manera cómoda\n",
    "    matriz = np.array(flat_list)\n",
    "    \n",
    "    return matriz, secuencias, listado, orden"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e11078b",
   "metadata": {},
   "source": [
    "Y pasamos por la función todas las listas que hayamos creado anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2de11e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creamos las listas de entrenamiento, testeo y validación\n",
    "if(\"direcciones_Train\" in globals()):\n",
    "    print('\\033[1m'+'Set de entrenamiento'+'\\033[0m')\n",
    "    str_info = str_info + \"\\n\\u25BA Extracción de datos del set de entrenamiento \\u25C4\\n\"\n",
    "    matriz_Train, secuencias_Train, listado_base_Train, orden_Train = Saca_matrices(direcciones_Train)\n",
    "    print(\"Se ha creado la variable matriz_Train\")\n",
    "    \n",
    "else:\n",
    "    if(\"matriz_Train\" in globals()): del matriz_Train\n",
    "    if(\"secuencias_Train\" in globals()): del secuencias_Train\n",
    "    if(\"listado_base_Train\" in globals()): del listado_base_Train\n",
    "    if(\"orden_Train\" in globals()):del orden_Train\n",
    "\n",
    "if(\"direcciones_Test\" in globals()):\n",
    "    print('\\033[1m'+'Set de testeo'+'\\033[0m')\n",
    "    str_info = str_info + \"\\n\\u25BA Extracción de datos del set de testeo \\u25C4\\n\"\n",
    "    matriz_Test, secuencias_Test, listado_base_Test, orden_Test = Saca_matrices(direcciones_Test)\n",
    "    print(\"Se ha creado la variable matriz_Test\")\n",
    "else:\n",
    "    if(\"matriz_Test\" in globals()): del matriz_Test\n",
    "    if(\"secuencias_Test\" in globals()): del secuencias_Test\n",
    "    if(\"listado_base_Test\" in globals()): del listado_base_Test\n",
    "    if(\"orden_Test\" in globals()):del orden_Test\n",
    "        \n",
    "if(\"direcciones_Val\" in globals()):\n",
    "    print('\\033[1m'+'Set de validación'+'\\033[0m')\n",
    "    str_info = str_info + \"\\n\\u25BA Extracción de datos del set de validación \\u25C4\\n\"\n",
    "    matriz_Val, secuencias_Val, listado_base_Val, orden_Val = Saca_matrices(direcciones_Val)\n",
    "    print(\"Se ha creado la variable matriz_Val\")\n",
    "else:\n",
    "    if(\"matriz_Val\" in globals()): del matriz_Val\n",
    "    if(\"secuencias_Val\" in globals()): del secuencias_Val\n",
    "    if(\"listado_base_Val\" in globals()): del listado_base_Val\n",
    "    if(\"orden_Val\" in globals()):del orden_Val\n",
    "    \n",
    "#Recuento del tiempo\n",
    "tiempo_datos = time.time()\n",
    "tiempo_total = tiempo_datos-tiempo_inicio\n",
    "\n",
    "segundos=tiempo_total\n",
    " \n",
    "horas=int(segundos/3600)\n",
    "segundos-=horas*3600\n",
    "minutos=int(segundos/60)\n",
    "segundos-=int(minutos*60)\n",
    "segundos =int(segundos)\n",
    "\n",
    "print(\"\\n\\u23F3%s:%s:%s\" % (horas,minutos,segundos))\n",
    "str_info = str_info + \"\\n\\t\\u23F3 En total el proceso de extracción de datos ha tardado \" + str(horas) +\":\"+str(minutos)+\":\"+str(segundos)+\".\\n\" \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141464da",
   "metadata": {},
   "source": [
    "## Procesado de los datos\n",
    "\n",
    "Esta parte del código se encargará de procesar las matrices calculadas anteriormente para darlas el formato adecuado antes de exportarlas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7207cf51",
   "metadata": {},
   "source": [
    "### Obtención de las listas de AP's\n",
    "\n",
    "Lo primero será comprobar la existencia de alguna lista a la que aferrarse. En el caso de que exista los datos se acomodarán a ella, de lo contrario habrá distintas maneras de proceder.\n",
    "\n",
    "Para el caso del entrenamiento, si no hay una lista preestablicida (que es lo esperable) habrá que localizar los diferentes puntos de acceso que aparecen en todos los datos dentro de un conjunto, los cuales pueden no conincidir con los de otros conjuntos (por ejemplo los APs vistos en el entrenamiento pueden ser distintos de los vistos en el testeo).\n",
    "Los APs vistos en el entrenamiento marcaran el orden de la matriz, mientras que los de testeo y validación se tendran que ajustar a dicho orden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1194a203",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comprobamos si hay alguna lista y limpiamos las que haya (si tienen indices Latitud o Longitud los eliminamos)\n",
    "lista_listas=[\n",
    "    \"listado_base_Train\",\n",
    "    \"listado_base_Test\",\n",
    "    \"listado_base_Val\"\n",
    "]\n",
    "\n",
    "lista_filtros=[\n",
    "    \"Latitud\",\n",
    "    \"Longitud\"\n",
    "]\n",
    "\n",
    "str_info = str_info + \"\\n\\u25BA Obtención de las listas \\u25C4\\n\"\n",
    "\n",
    "for element in lista_listas:\n",
    "    if((element in globals()) & (element is not None)):\n",
    "        print(\"Se ha encontrado la lista: \"+str(element))\n",
    "        if (globals()['%s' % element] is None):\n",
    "            print(\"El elemento estaba vacio, así que pasamos a borrarlo\")\n",
    "            del (globals()['%s' % element])\n",
    "        else:\n",
    "            print(\"La lista está formada por \" +str(len(globals()['%s' % element]))+ \" APs. Mostramos las primeras 10 filas de la lista:\\n\" +str(globals()['%s' % element][0:10]))\n",
    "            str_info = str_info + \"Se ha encontrado la lista: \"+str(element) + \" formada por \" +str(len(globals()['%s' % element]))+ \" APs. Mostramos las primeras 10 filas de la lista:\\n\" +str(globals()['%s' % element][0:10]) +\"\\n\"\n",
    "            \n",
    "            #Revisamos que no haya columnas \"Latitud\" o \"Longitud\"\n",
    "            for filtro in lista_filtros:     \n",
    "                if(filtro in globals()[\"%s\"%element]):\n",
    "                    #print(\"Encontrada columna \"+filtro+\" en \" + element + \". Procedemos a borrarla.\")\n",
    "                    posicion = np.where(globals()[\"%s\"%element]==filtro)[0][0]\n",
    "                    #print(posicion)\n",
    "                    globals()[\"%s\"%element]=np.delete(globals()[\"%s\"%element], posicion)\n",
    "                    print(\"En la lista original se encontraron columnas que sobran ('Latitud o Longitud'), tras borrarlas nos quedamos con una lista base de tamaño \"+ str(len(globals()[\"%s\"%element])))\n",
    "                    str_info = str_info + \"En la lista original se encontraron columnas que sobran ('Latitud o Longitud'), tras borrarlas nos quedamos con una lista base de tamaño \"+ str(len(globals()[\"%s\"%element]))\n",
    "                    \n",
    "if(\"matriz_Train\" in globals()):\n",
    "    if(\"listado_base_Train\" not in globals()):\n",
    "        #Filtramos en función de las direcciones MAC, las cuales se presentan en la 3 columna\n",
    "        matriz_Aps = np.zeros(matriz_Train.shape[0])\n",
    "        matriz_Aps = matriz_Train[:,2]\n",
    "\n",
    "        #Nos quedamos solo con uno de cada para crear la lista\n",
    "        if(ordenar_listas==False):\n",
    "            #Si no queremos ordenar la lista mostramos las direcciones MAC conforme vayan apareciendo\n",
    "            print(\"Como ha seleccionado la opción para no ordenar la lista, se esta procesando usando un bucle for, por lo que este paso puede tomar un poco de tiempo.\")\n",
    "            Aps_unicos = []            \n",
    "            for element in matriz_Aps:\n",
    "                if element not in Aps_unicos: Aps_unicos.append(element)\n",
    "            Aps_unicos=np.array(Aps_unicos)\n",
    "            str_info = str_info + \"El listado con las direcciones MAC se ha procesado manualmente ya que ha seleccionado la opción de no ordenarlo.\"\n",
    "            \n",
    "        else:\n",
    "            Aps_unicos = np.unique(matriz_Aps)    \n",
    "            str_info = str_info + \"El listado ha sido ordenado de forma ascendente en función de las direcciones MAC.\"\n",
    "        \n",
    "        print(\"Entre los datos de entrenamiento se han encontrado un total de \"+ str(len(Aps_unicos))+\" direcciones MAC diferentes. \\nAquí te muestro las 10 primeras:\\n\"+ str(Aps_unicos[0:10]) )\n",
    "        listado_base_Train = Aps_unicos\n",
    "        \n",
    "        str_info = str_info + \"Hemos procesado los datos de entrenamiento. En total hemos detectado \" +str(len(Aps_unicos))+\" direcciones MAC únicas.\" + \"Aquí te muestro las 10 primeras:\\n\"+ str(Aps_unicos[0:10]) + \"\\n\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f13b0d53",
   "metadata": {},
   "source": [
    "### Funciónes para ordenar los datos\n",
    "Las siguientes funciones sirven para organizar los datos y crear las matrices finales con las que trabajaremos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a767f63a",
   "metadata": {},
   "source": [
    "En el caso de la matriz de entrenamiento esta recibe como parámetros:\n",
    "* Identificadores: Una array con las direcciones MAC únicas filtradas anteriormente\n",
    "* Matriz_scan: La matriz en la que aparecen los datos leidos de los csv creada anteriormente\n",
    "* Etiquetas_juntas (opcional): En caso de que este parámetro sea verdadero las etiquetas se incluirán en la matriz final, de lo contrario se crearán dos matrices separadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f880988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Organizador_entrenamiento(matriz_scan, secuencias, identificadores, etiquetas_juntas=False, add_time=False):\n",
    "    #En la primera columna de la matriz se almacena el número de escaneo, así que para saber cuantos escaneos hay leemos el valor de la primera columna de la última fila\n",
    "    numero_scaneos=sum(secuencias)+len(secuencias) #Como empiezan en 0 sumamos 1 por cada secuencia\n",
    "    print(\"Localizados \"+str(numero_scaneos)+\" escaneos distintos\")\n",
    "    globals()[\"str_info\"]=globals()[\"str_info\"] + \"Localizados \"+str(numero_scaneos)+\" escaneos distintos.\\n\"\n",
    "    \n",
    "    #Definimos el tamaño de la matriz con los APs\n",
    "    matriz_salida=np.ones((numero_scaneos,len(identificadores)))*(inv_value)\n",
    "    #Definimos el tamaño de la matriz de etiquetas\n",
    "    matriz_etiquetas=np.zeros((numero_scaneos,2))\n",
    "    #Definimos el tamaño de la matriz de tiempos. Como son strings hay que definir el tamaño de cada item\n",
    "    matriz_time=np.chararray((numero_scaneos,1),itemsize = 27, unicode = True)\n",
    "    \n",
    "    set_datos = 0\n",
    "    offset = 0\n",
    "    muestra_anterior = 0\n",
    "    \n",
    "    #Colocamos los datos de forma ordenada según aparezcan en la lista de identificadores\n",
    "    for ciclo, element in enumerate(matriz_scan):\n",
    "        #Nos aseguramos que la dirección MAC este en la lista, si no algo ha fallado\n",
    "        assert element[2] in identificadores.tolist(), \"La dirección MAC \"+str(element[2])+\" del elemento \"+str(ciclo)+\" no se había listado.\"\n",
    "        \n",
    "        if((int(element[0])!=int(muestra_anterior)) & (int(muestra_anterior) ==secuencias[set_datos])):\n",
    "            offset = offset + secuencias[set_datos] +1\n",
    "            set_datos=set_datos+1\n",
    "            \n",
    "        \n",
    "        fila = offset + int(element[0])\n",
    "        #print(fila, offset, int(element[0]),secuencias[set_datos])\n",
    "        columna = np.where(identificadores == element[2])\n",
    "        \n",
    "        matriz_salida[fila,int(columna[0])] = element[3]\n",
    "        matriz_etiquetas[fila] = [float(s) for s in re.findall(r'-?\\d+\\.?\\d*', str(element[5]))]\n",
    "\n",
    "        #Guardamos las marcas de tiempo\n",
    "        matriz_time[fila] = element[4]\n",
    "        #print(matriz_time[fila], type(element[4]), len(element[4]))\n",
    "        \n",
    "        muestra_anterior = element[0]\n",
    "        #print(\"Fila: \"+str(fila)+\" columna: \"+str(columna))\n",
    "    \n",
    "    listado = identificadores\n",
    "        \n",
    "    #Si está indicado que se añadan las etiquetas\n",
    "    if(etiquetas_juntas == True):\n",
    "        matriz_salida = np.concatenate((matriz_salida, matriz_etiquetas), axis=1)\n",
    "        matriz_etiquetas = None\n",
    "        listado = np.concatenate((listado, [\"Latitud\",\"Longitud\"]), axis=0)\n",
    "        \n",
    "    #Si está indicado que se añadan las marcas de tiempo\n",
    "    if(add_time == True):\n",
    "        print(\"He entrado en add time.\")\n",
    "        matriz_salida = np.concatenate((matriz_salida, matriz_time), axis=1)\n",
    "        matriz_time = None\n",
    "        listado = np.concatenate((listado, [\"Time stamp\"]), axis=0)\n",
    "    \n",
    "    return (matriz_salida, matriz_etiquetas, matriz_time, listado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b3cab0",
   "metadata": {},
   "source": [
    "En el caso del testeo y validación existen varias posibilidades:\n",
    "* En caso de que se le introduzca una lista de APs (por ejemplo la del entrenamiento) los datos se acomodarán a la misma, dejando a elección del usuario si borrar los APs que no aparezcan en la lista o si añadirlos al final.\n",
    "* Si no se introduce una lista base se procesará la misma y e acomodarán los datos.\n",
    "En lo que respecta a las etiquetas lo gestionamos al igual que en el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc20bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Organizador_general(matriz_scan, secuencias, identificadores=None, borrar_nuevos=False, etiquetas_juntas=False, add_time=False):\n",
    "    #En la primera columna de la matriz se almacena el número de escaneo, así que para saber cuantos escaneos hay leemos el valor de la primera columna de la última fila\n",
    "    numero_scaneos=sum(secuencias)+len(secuencias) #Como empiezan en 0 sumamos 1 por cada secuencia\n",
    "    print(\"Localizados \"+str(numero_scaneos)+\" escaneos distintos\")\n",
    "    globals()[\"str_info\"]=globals()[\"str_info\"] + \"Localizados \"+str(numero_scaneos)+\" escaneos distintos.\\n\"\n",
    "    \n",
    "    cuenta=0\n",
    "    set_datos = 0\n",
    "    offset = 0\n",
    "    muestra_anterior = 0\n",
    "    \n",
    "    #Si se ha introducido una lista de etiquetas debemos seguirla\n",
    "    if identificadores is not None:\n",
    "        lista_Aps = identificadores\n",
    "        print(\"La lista con los APs original era de tamaño \"+str(len(lista_Aps)))\n",
    "        \n",
    "        if(borrar_nuevos == False):\n",
    "            #Comprobamos si la direccion MAC pertenece al listado, y de no ser así la añadimos al final\n",
    "            for element in matriz_scan:\n",
    "                if(element[2] not in lista_Aps.tolist()):\n",
    "                    lista_Aps = np.append(lista_Aps, element[2])\n",
    "                    cuenta=cuenta+1\n",
    "                    #print(\"La señal: \"+str(element)+\" no pertenece al listado\")\n",
    "            print(\"Tras revisar los datos de entrada se han encontrado \"+str(cuenta)+\" APs nuevos, por lo que finalmente se han listado \"+str(len(lista_Aps))+\" Aps.\")\n",
    "            globals()[\"str_info\"]=globals()[\"str_info\"] + \"[Importante]: La lista con los APs original era de tamaño \"+str(len(identificadores))+ \". Tras revisar los datos de entrada se han encontrado \"+str(cuenta)+\" APs nuevos, por lo que finalmente se han listado \"+str(len(lista_Aps))+\" Aps.\\n\"\n",
    "\n",
    "        else:\n",
    "            print(\"[Importante]: Seleccionada la opción para omitir los APs que no aparezcan en la lista original (ya sea la introducida manualmente o la generada en el entrenamiento)\")\n",
    "            globals()[\"str_info\"]=globals()[\"str_info\"] + \"[Importante]: Seleccionada la opción para omitir los APs que no aparezcan en la lista original (ya sea la introducida manualmente o la generada en el entrenamiento)\"\n",
    "            \n",
    "    \n",
    "    #Si no se introduce una lista para organizar los AP creamos una propia\n",
    "    else:\n",
    "        #Creamos la lista de los diferentes APs\n",
    "        Aps_unicos = np.zeros(matriz_scan.shape[0])\n",
    "        Aps_unicos = matriz_scan[:,2]\n",
    "        \n",
    "        if(ordenar_listas==False):\n",
    "            #Si no queremos ordenar la lista mostramos las direcciones MAC conforme vayan apareciendo\n",
    "            print(\"Como ha seleccionado la opción para no ordenar la lista, se esta procesando usando un bucle for, por lo que este paso puede tomar un poco de tiempo.\")\n",
    "            lista_Aps = []            \n",
    "            for element in Aps_unicos:\n",
    "                if element not in lista_Aps: lista_Aps.append(element)\n",
    "            lista_Aps=np.array(lista_Aps)\n",
    "            \n",
    "        else:\n",
    "            lista_Aps = np.unique(Aps_unicos)\n",
    "        \n",
    "        print(\"No se ha introducido ninguna lista, por lo que se procede a organizar los APs conforme aparecen en los csv.\\nEn total se han encontrado \"+ str(len(Aps_unicos))+\" direcciones MAC diferentes. Aquí te muestro las 10 primeras:\\n\"+ str(Aps_unicos[0:10]) )\n",
    "        globals()[\"str_info\"]=globals()[\"str_info\"] + \"No se ha introducido ninguna lista, por lo que se procede a organizar los APs conforme aparecen en los csv.\\nEn total se han encontrado \"+ str(len(Aps_unicos))+\" direcciones MAC diferentes. Aquí te muestro las 10 primeras:\\n\"+ str(Aps_unicos[0:10])+\"\\n\"\n",
    "        \n",
    "    #Definimos el tamaño de la matriz con los APs\n",
    "    matriz_salida=np.ones((numero_scaneos,len(lista_Aps)))*(inv_value)\n",
    "    #Definimos el tamaño de la matriz de etiquetas\n",
    "    matriz_etiquetas=np.zeros((numero_scaneos,2))\n",
    "    #Definimos el tamaño de la matriz de tiempos\n",
    "    matriz_time=np.chararray((numero_scaneos,1),itemsize = 27, unicode = True)\n",
    "        \n",
    "    #Colocamos los datos de forma ordenada según aparezcan en la lista de identificadores\n",
    "    for ciclo, element in enumerate(matriz_scan):\n",
    "        \n",
    "        #Si no borras los APs fuera de la lista los pones al final según vayan apareciendo\n",
    "        if(borrar_nuevos == False):\n",
    "            #Nos aseguramos que la dirección MAC este en la lista, si no algo ha fallado\n",
    "            assert element[2] in lista_Aps.tolist(), \"La dirección MAC \"+str(element[2])+\" del elemento \"+str(ciclo)+\" no se había listado.\"\n",
    "\n",
    "            if((int(element[0])!=int(muestra_anterior)) & (int(muestra_anterior) ==secuencias[set_datos])):\n",
    "                offset = offset + secuencias[set_datos] +1\n",
    "                set_datos=set_datos+1\n",
    "\n",
    "            fila = offset + int(element[0])\n",
    "            #print(fila, offset, int(element[0]),secuencias[set_datos])\n",
    "            columna = np.where(lista_Aps == element[2])\n",
    "            #print(columna[0], element[2])\n",
    "            matriz_salida[fila,int(columna[0])] = element[3]\n",
    "            \n",
    "            #Si hay etiquetas\n",
    "            if(len(element) >= 5):\n",
    "                if(element[5][2]==\".\"):\n",
    "                    matriz_etiquetas[fila] = [float(s) for s in re.findall(r'-?\\d+\\.?\\d*', str(element[5]))]\n",
    "                    hay_etiquetas = True\n",
    "                   \n",
    "        \n",
    "        #Si quieres borrar los datos cuando aparezca un AP que no está en la lista no lo añades \n",
    "        else:\n",
    "            if((int(element[0])!=int(muestra_anterior)) & (int(muestra_anterior) ==secuencias[set_datos])):\n",
    "                offset = offset + secuencias[set_datos] +1\n",
    "                set_datos=set_datos+1\n",
    "\n",
    "            fila = offset + int(element[0])\n",
    "            #print(fila, offset, int(element[0]),secuencias[set_datos])\n",
    "            columna = np.where(lista_Aps == element[2])\n",
    "            #Si no ha encontrado el AP en la lista no lo añadimos\n",
    "            if (len(columna[0]) != 0):\n",
    "                #print(columna[0], element[2])\n",
    "                matriz_salida[fila,int(columna[0])] = element[3]\n",
    "        \n",
    "            #Si hay etiquetas\n",
    "            if(len(element) >= 5):\n",
    "                if(element[5][2]==\".\"):\n",
    "                    matriz_etiquetas[fila] = [float(s) for s in re.findall(r'-?\\d+\\.?\\d*', str(element[5]))]\n",
    "                    hay_etiquetas = True\n",
    "                    \n",
    "        muestra_anterior = element[0]\n",
    "        \n",
    "        #Guardamos las marcas de tiempo\n",
    "        matriz_time[int(element[0])] = element[4]\n",
    "            \n",
    "        \n",
    "\n",
    "    #Devolvemos el listado\n",
    "    listado = lista_Aps\n",
    "    \n",
    "    #Si está indicado que se añadan las etiquetas\n",
    "    if(etiquetas_juntas == True & (\"hay_etiquetas\" in locals())):\n",
    "        matriz_salida = np.concatenate((matriz_salida, matriz_etiquetas), axis=1)\n",
    "        matriz_etiquetas = None\n",
    "        listado = np.concatenate((listado, [\"Latitud\",\"Longitud\"]), axis=0)\n",
    "    \n",
    "    #Si está indicado que se añadan las marcas de tiempo\n",
    "    if(add_time == True):\n",
    "        matriz_salida = np.concatenate((matriz_salida, matriz_time), axis=1)\n",
    "        matriz_time = None\n",
    "        listado = np.concatenate((listado, [\"Time stamp\"]), axis=0)\n",
    "    \n",
    "    return (matriz_salida, matriz_etiquetas, matriz_time, listado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa32d261",
   "metadata": {},
   "source": [
    "### Obtención de las matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1e3e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_procesar=[\n",
    "    \"matriz_Train\",\n",
    "    \"matriz_Test\",\n",
    "    \"matriz_Val\"\n",
    "]\n",
    "\n",
    "str_info = str_info + \"\\n\\u25BA Obtención de las matrices \\u25C4\\n\"\n",
    "\n",
    "#Vamos procesando las matrices de una en una\n",
    "for element in lista_procesar:\n",
    "    if element in globals():\n",
    "        print(\"\\033[1m\" + str(element[7:])+ \"\\033[0m\")\n",
    "        str_info = str_info + str(element[7:]) +\"\\n\"\n",
    "        \n",
    "        #Si se trata del conjunto de entrenamiento sabemos que siempre tendremos una lista\n",
    "        if(\"Train\" in element):\n",
    "            globals()[\"matriz_\"+'%s'%element[7:]+\"_organizada\"], globals()[\"matriz_\"+'%s'%element[7:]+\"_etiquetas\"], globals()[\"matriz_\"+'%s'%element[7:]+\"_timestamp\"], globals()[\"listado_\"+'%s'%element[7:]] = Organizador_entrenamiento(globals()['%s'%element], globals()[\"secuencias_\"+'%s'%element[7:]], globals()[\"listado_base_\"+'%s'%element[7:]], etiquetas_juntas = globals()[\"junto_\"+'%s'%element[7:]], add_time=add_timestamp)\n",
    "        \n",
    "        #Si es el conjunto de testeo o validacion puede haber varios escenarios\n",
    "        else:\n",
    "            #Si tenemos una lista base le damos prioridad\n",
    "            if(\"listado_base_\"+ str(element[7:]) in globals()):\n",
    "                print(\"Matriz obtenida a partir de una lista base.\")\n",
    "                str_info = str_info + \"Matriz obtenida a partir de una lista base.\\n\"\n",
    "                globals()[\"matriz_\"+'%s'%element[7:]+\"_organizada\"], globals()[\"matriz_\"+'%s'%element[7:]+\"_etiquetas\"], globals()[\"matriz_\"+'%s'%element[7:]+\"_timestamp\"], globals()[\"listado_\"+'%s'%element[7:]] = Organizador_general(globals()['%s'%element], globals()[\"secuencias_\"+'%s'%element[7:]], globals()[\"listado_base_\"+'%s'%element[7:]], borrar_nuevos = globals()[\"borrar_datos_nuevos_\" +'%s'%element[7:]], etiquetas_juntas = globals()[\"junto_\"+'%s'%element[7:]], add_time=add_timestamp)\n",
    "            \n",
    "            #Si no tenemos lista base pero tenemos datos de entrenamiento lo lógico será que organizemos los datos siguiendo dicha lista    \n",
    "            elif(\"matriz_Train\" in globals()):\n",
    "                print(\"Matriz obtenida a partir de los datos de entrenamiento. Los AP's específicos de esta parte se encuentran al final\")\n",
    "                str_info = str_info + \"Matriz obtenida a partir de los datos de entrenamiento. Los AP's específicos de esta parte se encuentran al final.\\n\"\n",
    "                globals()[\"matriz_\"+'%s'%element[7:]+\"_organizada\"], globals()[\"matriz_\"+'%s'%element[7:]+\"_etiquetas\"], globals()[\"matriz_\"+'%s'%element[7:]+\"_timestamp\"], globals()[\"listado_\"+'%s'%element[7:]] = Organizador_general(globals()['%s'%element], globals()[\"secuencias_\"+'%s'%element[7:]], listado_base_Train, borrar_nuevos = globals()[\"borrar_datos_nuevos_\"+'%s'%element[7:]], etiquetas_juntas = globals()[\"junto_\"+'%s'%element[7:]], add_time=add_timestamp)\n",
    "            \n",
    "            #Si no estamos en ninguno de los casos anteriores no indicamos ningún orden\n",
    "            else:\n",
    "                print(\"Matriz obtenida a partir de los datos crudos sin ninguna referencia.\")\n",
    "                str_info = str_info + \"Matriz obtenida a partir de los datos crudos sin ninguna referencia.\\n\"\n",
    "                globals()[\"matriz_\"+'%s'%element[7:]+\"_organizada\"], globals()[\"matriz_\"+'%s'%element[7:]+\"_etiquetas\"], globals()[\"matriz_\"+'%s'%element[7:]+\"_timestamp\"], globals()[\"listado_\"+'%s'%element[7:]] = Organizador_general(globals()['%s'%element], globals()[\"secuencias_\"+'%s'%element[7:]], etiquetas_juntas = globals()[\"junto_\"+'%s'%element[7:]], add_time=add_timestamp)\n",
    "        \n",
    "        print(\"Resultado de tamaño \"+str(globals()[\"matriz_\"+'%s'%element[7:]+\"_organizada\"].shape[0])+ \"x\" +str(globals()[\"matriz_\"+'%s'%element[7:]+\"_organizada\"].shape[1])+\".\\n Aquí un ejemplo de las primeras 10 filas y columnas:\\n\"+ str(globals()[\"matriz_\"+'%s'%element[7:]+\"_organizada\"][:10,:10]))\n",
    "        str_info = str_info + \"Resultado de tamaño \"+str(globals()[\"matriz_\"+'%s'%element[7:]+\"_organizada\"].shape[0])+ \"x\" +str(globals()[\"matriz_\"+'%s'%element[7:]+\"_organizada\"].shape[1])+\".\\n Aquí un ejemplo de las primeras 10 filas y columnas:\\n\"+ str(globals()[\"matriz_\"+'%s'%element[7:]+\"_organizada\"][:10,:10]) + \"\\n\"\n",
    "\n",
    "#Recuento del tiempo\n",
    "tiempo_matriz = time.time()\n",
    "tiempo_total = tiempo_matriz-tiempo_inicio\n",
    "\n",
    "segundos=tiempo_total\n",
    " \n",
    "horas=int(segundos/3600)\n",
    "segundos-=horas*3600\n",
    "minutos=int(segundos/60)\n",
    "segundos-=int(minutos*60)\n",
    "segundos =int(segundos)\n",
    "\n",
    "print(\"\\n\\u23F3%s:%s:%s\" % (horas,minutos,segundos))\n",
    "str_info = str_info + \"\\n\\t\\u23F3 En total el procesado de la matriz ha tardado \" + str(horas) +\":\"+str(minutos)+\":\"+str(segundos)+\".\\n\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82f281c0",
   "metadata": {},
   "source": [
    "En el caso de que se haya procesado una matriz de entrenamiento se proporcionará feedback sobre el valor asignado a los puntos de acceso no visible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d797374",
   "metadata": {},
   "outputs": [],
   "source": [
    "if(check_minimun == True):\n",
    "    # Comprobamos los valores \n",
    "    if \"matriz_Train_organizada\" in globals():\n",
    "        if (junto_Train==True) & (add_timestamp==True):\n",
    "            valores = np.unique(matriz_Train_organizada[:,0:-3])\n",
    "        elif (junto_Train==True) & (add_timestamp==False):\n",
    "            valores = np.unique(matriz_Train_organizada[:,0:-2])\n",
    "        elif (junto_Train==False) & (add_timestamp==True):\n",
    "            valores = np.unique(matriz_Train_organizada[:,0:-1])\n",
    "        else:\n",
    "            valores = np.unique(matriz_Train_organizada)\n",
    "\n",
    "        maximo = np.amax(valores)\n",
    "        minimo = np.amin(valores)\n",
    "        print(maximo,minimo)\n",
    "        print(\"Los valores que han aparecido en la matriz de entrenamiento son\" + str(valores))\n",
    "        str_info = str_info + \"Los valores que han aparecido en la matriz de entrenamiento son\" + str(valores)+\"\\n\"\n",
    "\n",
    "        if(minimo < inv_value):\n",
    "            valores_menores = [valor for valor in valores if valor < inv_value]\n",
    "            val_y_frec = [str(\"Valor \" +str(valor)+\" aparece \"+str(np.count_nonzero(matriz_Train_organizada == valor))+\" veces.\") for valor in valores_menores]\n",
    "            print(\"\\t\\u2620Cuidado, has asignado un valor a los puntos de acceso no visbles que es menor que uno (o más) de los valores encontrados.\\nEsta es la lista de valores inferiores al asignado y la frecuencia con la que han aparecido cada uno de ellos: \"+str(val_y_frec))\n",
    "            str_info = str_info + \"\\t\\u2620Cuidado, has asignado un valor a los puntos de acceso no visbles que es menor que uno (o más) de los valores encontrados.\\nEsta es la lista de valores inferiores al asignado y la frecuencia con la que han aparecido cada uno de ellos: \"+str(val_y_frec) +\"\\n\"\n",
    "        else:\n",
    "            print(\"Ningún valor es inferior al asignado.\")\n",
    "            str_info = str_info + \"Ningún valor es inferior al asignado.\" + \"\\n\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6debaf6e",
   "metadata": {},
   "source": [
    "## Escritura de los datos procesados\n",
    "\n",
    "Finalmente, una vez todos los datos han sido procesados los volvemos a meter a un archivo .csv que localizaremos en la carpeta \"Processed_data\". Dentro de dicha carpeta creamos otra con la fecha actual, sobre la cual crearemos distintas carpetas con el nombre de la hora en la que se ha guardado información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5020b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finalmente creamos creamos las carpetas donde guardarán los datos\n",
    "if(os.path.exists(date_path)!=True):\n",
    "    os.mkdir(date_path)\n",
    "    \n",
    "#Dentro de dicha carpeta creamos otra con la hora en la cual guardaremos los resultados\n",
    "os.mkdir(hour_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79aa95d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creacion de los indices de las filas\n",
    "#print(secuencias_Train)\n",
    "lista_indices=[\n",
    "    \"index_Train\",\n",
    "    \"index_Test\",\n",
    "    \"index_Val\"\n",
    "]\n",
    "\n",
    "for indice in lista_indices:\n",
    "    \n",
    "    if(\"secuencias_\"+indice[6:] in globals()):\n",
    "        #print(\"secuencias_\"+indice[6:])\n",
    "        globals()[\"index_\"+str(indice[6:])]=[]\n",
    "\n",
    "        for secuencia in globals()[\"secuencias_\"+indice[6:]]:\n",
    "            globals()[\"index_\"+str(indice[6:])] = globals()[\"index_\"+str(indice[6:])] + list(range(secuencia+1))\n",
    "\n",
    "    \n",
    "#print(len(index_Train), index_Train)\n",
    "#print(len(index_Test), index_Test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1648a446",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pasamos cada matriz a csv y las guardamos en la carpeta.\n",
    "lista_matrices =[\n",
    "    \"matriz_Train_organizada\",\n",
    "    \"matriz_Train_etiquetas\",\n",
    "    \"matriz_Train_timestamp\",\n",
    "    \"matriz_Test_organizada\",\n",
    "    \"matriz_Test_etiquetas\",\n",
    "    \"matriz_Test_timestamp\",\n",
    "    \"matriz_Val_organizada\",\n",
    "    \"matriz_Val_etiquetas\",\n",
    "    \"matriz_Val_timestamp\",\n",
    "    \"listado_Train\",\n",
    "    \"listado_Test\",\n",
    "    \"listado_Val\",\n",
    "    \"orden_Train\",\n",
    "    \"orden_Test\",\n",
    "    \"orden_Val\"\n",
    "]\n",
    "\n",
    "for matriz in lista_matrices:    \n",
    "    #Comprobamos si la matriz existe\n",
    "    if (matriz in globals()):\n",
    "        #Si existe comprobamos si no está vacía\n",
    "        if(globals()['%s' % matriz] is not None):\n",
    "            file_path = hour_path + \"/\" + matriz + \".csv\"\n",
    "            \n",
    "            if(matriz[:7] == \"listado\"):\n",
    "                (pd.DataFrame(globals()['%s' % matriz])).to_csv(file_path, index=False, header=False)\n",
    "            \n",
    "            elif(matriz[-16:]==\"Train_organizada\"):\n",
    "                (pd.DataFrame(globals()['%s' % matriz], index = index_Train, columns= listado_Train)).to_csv(file_path)\n",
    "            \n",
    "            elif((\"etiquetas\" in matriz) or (\"timestamp\" in matriz)):\n",
    "                \n",
    "                if(\"etiquetas\" in matriz):\n",
    "                    col = [\"Latitud\", \"Longitud\"]\n",
    "                elif(\"timestamp\" in matriz):\n",
    "                    col = [\"Marca de tiempo\"]\n",
    "                    \n",
    "                if (\"Train\" in matriz):\n",
    "                    ind = index_Train\n",
    "                elif(\"Test\" in matriz):\n",
    "                    ind = index_Test\n",
    "                elif(\"Val\" in matriz):\n",
    "                    ind = index_Val\n",
    "                else:\n",
    "                    ind=False\n",
    "                \n",
    "                (pd.DataFrame(globals()['%s' % matriz],index = ind, columns = col)).to_csv(file_path)\n",
    "            \n",
    "            elif(\"Test_organizada\" in matriz):\n",
    "                (pd.DataFrame(globals()['%s' % matriz], index = index_Test, columns= listado_Test)).to_csv(file_path)\n",
    "            \n",
    "            elif(\"Val_organizada\" in matriz):\n",
    "                (pd.DataFrame(globals()['%s' % matriz], index = index_Val, columns= listado_Val)).to_csv(file_path)\n",
    "            \n",
    "            elif(\"orden\" in matriz):\n",
    "                (pd.DataFrame(globals()['%s' % matriz])).to_csv(file_path, index=False, header=False)\n",
    "                \n",
    "            else:\n",
    "                (pd.DataFrame(globals()['%s' % matriz])).to_csv(file_path, index=False)\n",
    "\n",
    "            #(pd.DataFrame(globals()['%s' % matriz])).to_csv(file_path, index=False)\n",
    "            print(str(matriz) + \" guardada en \" +file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45e35ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recuento del tiempo\n",
    "tiempo_fin = time.time()\n",
    "tiempo_total = tiempo_fin-tiempo_inicio\n",
    "\n",
    "segundos=tiempo_total\n",
    " \n",
    "horas=int(segundos/3600)\n",
    "segundos-=horas*3600\n",
    "minutos=int(segundos/60)\n",
    "segundos-=int(minutos*60)\n",
    "segundos =int(segundos)\n",
    "\n",
    "print(\"\\n\\u23F3%s:%s:%s\" % (horas,minutos,segundos))\n",
    "str_info = str_info + \"\\u23F3 En total el programa ha tardado \" + str(horas) +\":\"+str(minutos)+\":\"+str(segundos)+\".\\n\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa9e3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Escribimos el .txt\n",
    "informacion = open(hour_path + \"/informacion.txt\", \"w\")\n",
    "informacion.write(str_info)\n",
    "informacion.close()\n",
    "\n",
    "#Acabamos el programa\n",
    "print(\"\\033[1mPrograma finalizado con éxito\\033[0m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc41c48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
