{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ba78d15",
   "metadata": {},
   "source": [
    "# Script para gestionar el procesadoo de la base de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645c0c97",
   "metadata": {},
   "source": [
    "El objetivo es crear un script capaz de gestionar los archivos csv que se coloquen en una carpeta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d79b73",
   "metadata": {},
   "source": [
    "## Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "642d646f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para gestionar el directorio\n",
    "import os\n",
    "import time\n",
    "\n",
    "#Para filtrar los datos\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c775b7f0",
   "metadata": {},
   "source": [
    "## Creación del espacio de trabajo\n",
    "Esta parte del código se encargará de crear las diferentes carpetas en las que se almacenarán los datos procesados. Para ello lo primero que haremos en verificar si ya existe la configuración adecuada, y de no ser así se creará, indicando al usuario como ha de proceder.\n",
    "La idea es que el arbol de trabajo sea el siguiente:\n",
    "\n",
    "    |->Database\n",
    "        |->Raw_data\n",
    "            |->Unlisted_data\n",
    "            |->Train\n",
    "            |->Test\n",
    "            |->Val\n",
    "        |->Processed_data\n",
    "            |->Dia\n",
    "                |->Hora\n",
    "            \n",
    "En la carpeta \"Raw_data\" es donde irían los .csv que se van a procesar. Dentro de la misma hay varias opciones a la hora de procesar los datos:\n",
    "* Si se añaden csv en las carpetas \"Train\", \"Test\" y \"Val\" esos datos se usarán para dicho proceso.\n",
    "* Si se añaden listas que contengan \"listado\" en el nombre a alguna de las carpetas los datos de ese conjunto se procesaran siguiendo dicho listado.\n",
    "\n",
    "Finalmente los datos procesados se pueden recoger en la carpeta \"Processed_data\". Para evitar que se sobreescriban los datos se crea una carpeta cada vez que se lanza el programa, en la cual se indica el día (carpeta general) y la hora (subcarpeta en la que se guardan los datos procesados).\n",
    "\n",
    "En la carpeta de datos procesados siempre encontraras uno o varios archivos .csv (dependiendo de cuantos conjuntos vayas a crear y de si quieres las etiquetes juntas o separadas), junto con el listado de los AP's únicos que se ha usado para procesarlos y un .txt con información diversa del proceso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdcdaead",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Función para crear las carpetas a partir de una lista de direcciones\n",
    "def Crea_directorios(lista):\n",
    "  for direccion in lista:\n",
    "    os.mkdir(direccion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b49ec653",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encontrada la carpeta 'Database'. Procedemos a verificar que es la adecuada.\n",
      "\u001b[1mCarpeta identificada con éxito.\u001b[0m\n",
      "\u001b[1m[info]\u001b[0m: Por favor, diríjase a la dirección: '/home/laura/Adrian/Procesaor_dataset/Database' e ingrese los archivos .csv en la carpeta 'Raw_data' para continuar.\n",
      "Dentro de esa carpeta encontrará varias opciones, coloque los .csv en las carpetas de las que quiera crear un conjunto.\n",
      "Por ejemplo, si ingresa 2 archivos en la carpeta 'Train' ambos se procesaran como datos de entrenamiento, y si además mete otro dos en la carpeta 'Test' estos archivos se procesaran aparte en un conjunto de testeo.\n",
      "\u001b[1m[info]\u001b[0m: También puede meter un listado base con los AP's conforme los quieras colocar. Los datos se procesaran teniendo en cuenta esa lista.\n",
      "\u001b[1m[importante]\u001b[0m: Si quieres meter un listado en alguna carpeta asegurate de que este contenga el nombre 'listado'.\n",
      "\u001b[1m[info]\u001b[0m: Los archivos que queden fuera de alguna de estas carpetas no seran procesados.\n",
      "\u001b[1m[importante]\u001b[0m: Por favor, no introduzca nada en la carpeta 'Unlisted_data'.\n",
      "Cuando tengas todo listo pulsa el botón 'Enter' y procederemos con el procesado de los datos.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Definimos todas las direcciones necesarias.\n",
    "current_path = os.getcwd()\n",
    "external_path = current_path + \"/Database\"\n",
    "\n",
    "raw_path = external_path + \"/Raw_data\"\n",
    "raw_unlisted_path = raw_path + \"/Unlisted_data\"\n",
    "raw_train_path = raw_path + \"/Train\"\n",
    "raw_test_path = raw_path + \"/Test\"\n",
    "raw_val_path = raw_path + \"/Val\"\n",
    "\n",
    "#Y las direcciones de los archivos de salida\n",
    "processed_path = external_path + \"/Processed_data\"\n",
    "str_date = str(time.gmtime().tm_mday)+\"_\"+str(time.gmtime().tm_mon)+\"_\"+str(time.gmtime().tm_year)\n",
    "str_hour = str(time.gmtime().tm_hour)+\":\"+str(time.gmtime().tm_min)+\":\"+str(time.gmtime().tm_sec)\n",
    "date_path = processed_path + \"/\" + str_date\n",
    "hour_path = date_path + \"/\" + str_hour\n",
    "\n",
    "#Para la informacion\n",
    "str_info = (\"Información sobre el procesado de datos ejecutado el día \" + str(str_date) + \" a las \" +str(str_hour) +\".\\n\")\n",
    "\n",
    "lista_direcciones=[external_path,raw_path,raw_unlisted_path,raw_train_path,raw_test_path,raw_val_path,processed_path]\n",
    "\n",
    "#Primero comprobamos si existe la carpeta adecuada. \n",
    "if(os.path.exists(external_path)):\n",
    "    print(\"Encontrada la carpeta 'Database'. Procedemos a verificar que es la adecuada.\")\n",
    "    if(os.path.exists(raw_path) & os.path.exists(processed_path)):\n",
    "        if(os.path.exists(raw_unlisted_path) & os.path.exists(raw_train_path) & os.path.exists(raw_test_path) & os.path.exists(raw_val_path)):\n",
    "            print('\\033[1mCarpeta identificada con éxito.\\033[0m')\n",
    "        else:\n",
    "            print(\"Parece que hay un error. El arbol de trabajo es incorrecto, lo cual podría indicar que la carpeta 'Database' fue creada con otro fin. Procedo a cambiarla el nombre a 'Database_antigua' y creo un nuevo directorio con la configuración adecuada.\")\n",
    "            os.rename(external_path, external_path+'_antigua_' + str(time.time()))\n",
    "            Crea_directorios(lista_direcciones)\n",
    "            \n",
    "    else:\n",
    "        print(\"Parece que hay un error. El arbol de trabajo es incorrecto, lo cual podría indicar que la carpeta 'Database' fue creada con otro fin. Procedo a cambiarla el nombre a 'Database_antigua' y creo un nuevo directorio con la configuración adecuada.\")\n",
    "        os.rename(external_path, external_path+'_antigua_' + str(time.time()))\n",
    "        Crea_directorios(lista_direcciones)\n",
    "\n",
    "else:\n",
    "    print(\"No se ha encontrado la carpeta 'Database'. Se procede a crear todos los directorios.\")\n",
    "    Crea_directorios(lista_direcciones)    \n",
    "    print(\"El arbol de trabajo ya ha sido creado.\")\n",
    "    \n",
    "print(\"\\033[1m[info]\\033[0m: Por favor, diríjase a la dirección: '\"+ str(external_path) +\"' e ingrese los archivos .csv en la carpeta 'Raw_data' para continuar.\")\n",
    "print(\"Dentro de esa carpeta encontrará varias opciones, coloque los .csv en las carpetas de las que quiera crear un conjunto.\")\n",
    "print(\"Por ejemplo, si ingresa 2 archivos en la carpeta 'Train' ambos se procesaran como datos de entrenamiento, y si además mete otro dos en la carpeta 'Test' estos archivos se procesaran aparte en un conjunto de testeo.\")\n",
    "print(\"\\033[1m[info]\\033[0m: También puede meter un listado base con los AP's conforme los quieras colocar. Los datos se procesaran teniendo en cuenta esa lista.\")\n",
    "print(\"\\033[1m[importante]\\033[0m: Si quieres meter un listado en alguna carpeta asegurate de que este contenga el nombre 'listado'.\")\n",
    "print(\"\\033[1m[info]\\033[0m: Los archivos que queden fuera de alguna de estas carpetas no seran procesados.\")\n",
    "print(\"\\033[1m[importante]\\033[0m: Por favor, no introduzca nada en la carpeta 'Unlisted_data'.\")\n",
    "#print(\"Pd: Puede hacer ambas cosas a la vez.\")\n",
    "\n",
    "#Creamos una espera por si no se han metido los datos\n",
    "input(\"Cuando tengas todo listo pulsa el botón \\033[1m'Enter'\\033[0m y procederemos con el procesado de los datos.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54049032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empezamos a contar para saber cuanto tardamos en ejecutar el programa\n",
    "tiempo_inicio = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4a8b7a",
   "metadata": {},
   "source": [
    "## Obtención de los datos\n",
    "En esta parte del código  trabajaremos en los archivos .csv que se encuentren en la carpeta \"Raw_data\". La idea es que el código lea todos los archivos que encuentre y los procese, independientemente de la cantidad, por lo que el usuario es libre de meter cuantos archivos quiera."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2370203b",
   "metadata": {},
   "source": [
    "### Carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3766b5",
   "metadata": {},
   "source": [
    "Primero comprobamos que haya algún dato a procesar en alguna de las carpetas, y de no ser así avisamos al usuario para que los meta. \n",
    "Dejamos listadas las ubicaciones para facilitar su procesado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6e911426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La carpeta '\u001b[1mUnlisted_data\u001b[0m' esta vacia.\n",
      "Se han encontrado los siguientes archivos en la carpeta '\u001b[1mTrain\u001b[0m':\n",
      "\t ⏺t2_Nexus.csv\n",
      "\t ⏺t1_Nexus.csv\n",
      "Ya han sido listados.\n",
      "Se han encontrado los siguientes archivos en la carpeta '\u001b[1mTest\u001b[0m':\n",
      "\t ⏺t3_Nexus.csv\n",
      "\t ⏺listado_Train.csv\n",
      "Ya han sido listados.\n",
      "La carpeta '\u001b[1mVal\u001b[0m' esta vacia.\n",
      "Registro finalizado con éxito. Procedemos a extraer los datos de ['Train', 'Test']\n"
     ]
    }
   ],
   "source": [
    "Lista_procesar=[]\n",
    "\n",
    "#Unlisted\n",
    "if(len(os.listdir(raw_unlisted_path))==0):\n",
    "    print(\"La carpeta '\\033[1mUnlisted_data\\033[0m' esta vacia.\")\n",
    "else:\n",
    "    print(\"Se han encontrado los siguientes archivos en la carpeta '\\033[1mUnlisted_data\\033[0m':\")\n",
    "    for file in os.listdir(raw_unlisted_path):\n",
    "        print(file)\n",
    "    print(\"Ya ha sido listado.\" if len(os.listdir(raw_unlisted_path))==1 else \"Ya han sido listados.\")    \n",
    "    Lista_procesar.append(\"Unlisted_data\")\n",
    "\n",
    "#Train\n",
    "if(len(os.listdir(raw_train_path))==0):\n",
    "    print(\"La carpeta '\\033[1mTrain\\033[0m' esta vacia.\")\n",
    "else:\n",
    "    print(\"Se han encontrado los siguientes archivos en la carpeta '\\033[1mTrain\\033[0m':\")\n",
    "    \n",
    "    str_info = str_info +\"Se han extraido datos de los siguientes archivos localizados en la carpeta 'Train':\\n\"   \n",
    "    \n",
    "    for file in os.listdir(raw_train_path):\n",
    "        print(\"\\t \\u23FA\"+str(file))\n",
    "        str_info = str_info + \"\\t \\u23FA\"+ str(file) +\"\\n\"\n",
    "    \n",
    "    print(\"Ya ha sido listado.\" if len(os.listdir(raw_train_path))==1 else \"Ya han sido listados.\")    \n",
    "    Lista_procesar.append(\"Train\")\n",
    "    \n",
    "#Test\n",
    "if(len(os.listdir(raw_test_path))==0):\n",
    "    print(\"La carpeta '\\033[1mTest\\033[0m' esta vacia.\")\n",
    "else:\n",
    "    print(\"Se han encontrado los siguientes archivos en la carpeta '\\033[1mTest\\033[0m':\")\n",
    "    \n",
    "    str_info = str_info +\"Se han extraido datos de los siguientes archivos localizados en la carpeta 'Test':\\n\"\n",
    "    \n",
    "    for file in os.listdir(raw_test_path):\n",
    "        print(\"\\t \\u23FA\"+str(file))\n",
    "        str_info = str_info + \"\\t \\u23FA\"+ str(file) +\"\\n\"\n",
    "        \n",
    "    print(\"Ya ha sido listado.\" if len(os.listdir(raw_test_path))==1 else \"Ya han sido listados.\")    \n",
    "    Lista_procesar.append(\"Test\")\n",
    "\n",
    "#Val    \n",
    "if(len(os.listdir(raw_val_path))==0):\n",
    "    print(\"La carpeta '\\033[1mVal\\033[0m' esta vacia.\")    \n",
    "else:\n",
    "    print(\"Se han encontrado los siguientes archivos en la carpeta '\\033[1mVal\\033[0m':\")\n",
    "    \n",
    "    str_info = str_info +\"Se han extraido datos de los siguientes archivos localizados en la carpeta 'Val':\\n\"\n",
    "    \n",
    "    \n",
    "    for file in os.listdir(raw_val_path):\n",
    "        print(\"\\t \\u23FA\"+str(file))\n",
    "        str_info = str_info + \"\\t \\u23FA\"+ str(file) +\"\\n\"\n",
    "        \n",
    "    print(\"Ya ha sido listado.\" if len(os.listdir(raw_val_path))==1 else \"Ya han sido listados.\")    \n",
    "    Lista_procesar.append(\"Val\")\n",
    "\n",
    "#Verificamos que al menos una de las carpetas este vacia, si no avisamos al usuario para que meta los datos\n",
    "assert len(Lista_procesar) != 0, \"No se han encontrado datos en ninguna carpeta. Por favor introduzca algún csv.\"\n",
    "print(\"Registro finalizado con éxito. Procedemos a extraer los datos de \"+ str(Lista_procesar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "16e14527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No hay datos sin listar.\n"
     ]
    }
   ],
   "source": [
    "#Borramos las variables para que no den problemas en caso de que no existan.\n",
    "if(\"direcciones_Train\" in globals()):\n",
    "  del direcciones_Train\n",
    "if(\"direcciones_Test\" in globals()):\n",
    "  del direcciones_Test\n",
    "if(\"direcciones_Val\" in globals()):\n",
    "  del direcciones_Val\n",
    "if(\"direcciones_Unlisted_data\" in globals()):\n",
    "  del direcciones_Unlisted_data\n",
    "\n",
    "#Si no hay nada en \"unlisted_data\" podemos extraer los datos libremente\n",
    "if (\"Unlisted_data\" not in Lista_procesar):\n",
    "    print(\"No hay datos sin listar.\")\n",
    "    for elemento in Lista_procesar:\n",
    "        #globals()['direcciones_%s' % elemento] = [files for files in os.listdir(raw_path + \"/\" + elemento)]\n",
    "        path = raw_path + \"/\" + elemento\n",
    "        globals()['direcciones_%s' % elemento] =  [path +\"/\" + files for files in os.listdir(path)]\n",
    "\n",
    "else:\n",
    "    print(\"Si que esta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4756ec",
   "metadata": {},
   "source": [
    "### Función para sacar las matrices\n",
    "\n",
    "Una vez tenemos listadas las direcciones de todos los archivos que vamos a procesar, creamos una función que tendrá como entrada ese listado y como salida una matriz con todos datos.\n",
    "La variable \"secuencia\" cuenta con las muestras que tiene cada fichero csv, de forma que acaba siendo una lista donde se guardan todas las secuencias que se han procesado.\n",
    "También en el caso de que exista un fichero \"listado\" en alguna de las carpetas lo procesará para que se puedan ordenar los datos conforme allí aparezcan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "754a4304",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Saca_matrices(direcciones):\n",
    "    #Almacenaremos los datos en una lista de listas de tamaño variable en función de la cantidad de ficheros que haya\n",
    "    datos_totales=[]\n",
    "    secuencias=[]\n",
    "    listado = None\n",
    "    \n",
    "    #Para cargar los datos usamos pd.read_csv(), el cual nos carga los datos en formato Dataframe, pero nosotros lo convertiremos a lista para poder trabajar con ello\n",
    "    for direccion in direcciones:\n",
    "        #Comprobamos que no sea un archivo de listado\n",
    "        if(\"listado\" in direccion):\n",
    "            listado = pd.read_csv(direccion, header = None).to_numpy()[1:]\n",
    "            listado = np.array([item for sublist in listado for item in sublist])\n",
    "            print(\"[Importante]: Se ha encontrado una lista base\")\n",
    "            globals()[\"str_info\"]=globals()[\"str_info\"] + \"[Importante]: Se ha encontrado una lista base\\n\"\n",
    "        else:\n",
    "           datos_totales.append((pd.read_csv(direccion, header = None)).to_numpy().tolist())\n",
    "    \n",
    "    #Mostramos la cantidad de datos que se han leido para asegurarnos más tarde de que no se pierda ninguno\n",
    "    print(\"En total se han descargado \"+ str(len(datos_totales)) +\" ficheros, los cuales tienen las siguientes dimensiones:\")\n",
    "    globals()[\"str_info\"]=globals()[\"str_info\"] + \"En total se han descargado \"+ str(len(datos_totales)) +\" ficheros, los cuales tienen las siguientes dimensiones:\\n\"\n",
    "    \n",
    "    cuenta_datos = 0\n",
    "    for i in range(len(datos_totales)):\n",
    "        print(\"El archivo '\"+ str(direcciones[i]) +\" contenía \"+ str(len(datos_totales[i])) +\" datos.\")\n",
    "        print(\"En total representaban \"+str(datos_totales[i][-1][0])+\" secuencias.\")\n",
    "        globals()[\"str_info\"]=globals()[\"str_info\"] + \"\\t\\u23FA\" + \"El archivo '\"+ str(direcciones[i]) +\" contenía \"+ str(len(datos_totales[i])) +\" datos, los cuales en total representaban \"+str(datos_totales[i][-1][0] +1)+\" secuencias.\\n\"\n",
    "        cuenta_datos = cuenta_datos + len(datos_totales[i])\n",
    "        secuencias.append(datos_totales[i][-1][0])\n",
    "    print(\"Por lo que el total de datos a procesar tiene que ser de \"+str(cuenta_datos))\n",
    "    \n",
    "    #Una vez cargados los datos los pasaremos de una lista de listas a una sola lista\n",
    "    flat_list = [item for sublist in datos_totales for item in sublist]\n",
    "    print(\"Al realizar el 'aplanamiento' nos quedamos con un total de \"+ str(len(flat_list)))\n",
    "    assert len(flat_list) == cuenta_datos, \"Ha surgido un error al aplanar los datos. Originalmente había \"+ str(cuenta_datos) +\", pero tras aplanar nos hemos quedado con \"+ str(len(flat_list)) +\".Por favor, revisa el código\"\n",
    "    \n",
    "    #Escribimos más informacion\n",
    "    globals()[\"str_info\"]=globals()[\"str_info\"] + \"El total de datos a procesar dentro de este conjunto ha de ser de \"+str(cuenta_datos)+ \".\\n\"\n",
    "    \n",
    "    #Finalmente convertimos dicha lista a formato matriz para poder trabajar con ella de manera cómoda\n",
    "    matriz = np.array(flat_list)\n",
    "    \n",
    "    return matriz, secuencias, listado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e11078b",
   "metadata": {},
   "source": [
    "Y pasamos por la función todas las listas que hayamos creado anteriormente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2de11e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mSet de entrenamiento\u001b[0m\n",
      "En total se han descargado 2 ficheros, los cuales tienen las siguientes dimensiones:\n",
      "El archivo '/home/laura/Adrian/Procesaor_dataset/Database/Raw_data/Train/t2_Nexus.csv contenía 3711 datos.\n",
      "En total representaban 134 secuencias.\n",
      "El archivo '/home/laura/Adrian/Procesaor_dataset/Database/Raw_data/Train/t1_Nexus.csv contenía 4305 datos.\n",
      "En total representaban 128 secuencias.\n",
      "Por lo que el total de datos a procesar tiene que ser de 8016\n",
      "Al realizar el 'aplanamiento' nos quedamos con un total de 8016\n",
      "Se ha creado la variable matriz_Train\n",
      "\u001b[1mSet de testeo\u001b[0m\n",
      "[Importante]: Se ha encontrado una lista base\n",
      "En total se han descargado 1 ficheros, los cuales tienen las siguientes dimensiones:\n",
      "El archivo '/home/laura/Adrian/Procesaor_dataset/Database/Raw_data/Test/t3_Nexus.csv contenía 2870 datos.\n",
      "En total representaban 107 secuencias.\n",
      "Por lo que el total de datos a procesar tiene que ser de 2870\n",
      "Al realizar el 'aplanamiento' nos quedamos con un total de 2870\n",
      "Se ha creado la variable matriz_Test\n"
     ]
    }
   ],
   "source": [
    "#Creamos las listas de entrenamiento, testeo y validación\n",
    "if(\"direcciones_Train\" in globals()):\n",
    "    print('\\033[1m'+'Set de entrenamiento'+'\\033[0m')\n",
    "    str_info = str_info + \"Set de entrenamiento\\n\"\n",
    "    matriz_Train, secuencias_Train, listado_base_Train = Saca_matrices(direcciones_Train)\n",
    "    print(\"Se ha creado la variable matriz_Train\")\n",
    "else:\n",
    "    if(\"matriz_Train\" in globals()): del matriz_Train\n",
    "    if(\"secuencias_Train\" in globals()): del secuencias_Train\n",
    "    if(\"listado_base_Train\" in globals()): del listado_base_Train\n",
    "\n",
    "if(\"direcciones_Test\" in globals()):\n",
    "    print('\\033[1m'+'Set de testeo'+'\\033[0m')\n",
    "    str_info = str_info + \"Set de testeo\\n\"\n",
    "    matriz_Test, secuencias_Test, listado_base_Test = Saca_matrices(direcciones_Test)\n",
    "    print(\"Se ha creado la variable matriz_Test\")\n",
    "else:\n",
    "    if(\"matriz_Test\" in globals()): del matriz_Test\n",
    "    if(\"secuencias_Test\" in globals()): del secuencias_Test\n",
    "    if(\"listado_base_Test\" in globals()): del listado_base_Test\n",
    "\n",
    "if(\"direcciones_Val\" in globals()):\n",
    "    print('\\033[1m'+'Set de validación'+'\\033[0m')\n",
    "    str_info = str_info + \"Set de validación\\n\"\n",
    "    matriz_Val, secuencias_Val, listado_base_Val = Saca_matrices(direcciones_Val)\n",
    "    print(\"Se ha creado la variable matriz_Val\")\n",
    "else:\n",
    "    if(\"matriz_Val\" in globals()): del matriz_Val\n",
    "    if(\"secuencias_Val\" in globals()): del secuencias_Val\n",
    "    if(\"listado_base_Val\" in globals()): del listado_base_Val\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8835d9",
   "metadata": {},
   "source": [
    "## Procesado de los datos\n",
    "\n",
    "Esta parte del código se encargará de procesar las matrices calculadas anteriormente para darlas el formato adecuado antes de exportarlas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2161ff17",
   "metadata": {},
   "source": [
    "### Obtención de las listas de AP's\n",
    "\n",
    "Lo primero será comprobar la existencia de alguna lista a la que aferrarse. En el caso de que exista los datos se acomodarán a ella, de lo contrario habrá distintas maneras de proceder.\n",
    "\n",
    "Para el caso del entrenamiento, si no hay una lista preestablicida (que es lo esperable) habrá que localizar los diferentes puntos de acceso que aparecen en todos los datos dentro de un conjunto, los cuales pueden no conincidir con los de otros conjuntos (por ejemplo los APs vistos en el entrenamiento pueden ser distintos de los vistos en el testeo).\n",
    "Los APs vistos en el entrenamiento marcaran el orden de la matriz, mientras que los de testeo y validación se tendran que ajustar a dicho orden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36e22613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se ha encontrado la lista: listado_base_Train\n",
      "El elemento estaba vacio, así que pasamos a borrarlo\n",
      "Se ha encontrado la lista: listado_base_Test\n",
      "La lista está formada por 465 APs. Mostramos las primeras 10 filas de la lista:\n",
      "['00:31:92:26:81:ff' '00:4a:77:ec:31:b6' '00:4a:77:ec:31:b7'\n",
      " '00:e0:20:1f:a0:e3' '02:68:eb:6f:fa:e0' '04:a2:22:0e:b0:bc'\n",
      " '04:a2:22:20:ee:42' '04:a2:22:71:43:10' '06:31:92:26:81:92'\n",
      " '06:31:92:26:81:93']\n",
      "En la lista original se encontraron columnas que sobran ('Latitud o Longitud'), tras borrarlas nos quedamos con una lista base de tamaño 464\n",
      "En la lista original se encontraron columnas que sobran ('Latitud o Longitud'), tras borrarlas nos quedamos con una lista base de tamaño 463\n",
      "Entre los datos de entrenamiento se han encontrado un total de 463 direcciones MAC diferentes. \n",
      "Aquí te muestro las 10 primeras:\n",
      "['00:31:92:26:81:ff' '00:4a:77:ec:31:b6' '00:4a:77:ec:31:b7'\n",
      " '00:e0:20:1f:a0:e3' '02:68:eb:6f:fa:e0' '04:a2:22:0e:b0:bc'\n",
      " '04:a2:22:20:ee:42' '04:a2:22:71:43:10' '06:31:92:26:81:92'\n",
      " '06:31:92:26:81:93']\n"
     ]
    }
   ],
   "source": [
    "#Comprobamos si hay alguna lista y limpiamos las que haya (si tienen indices Latitud o Longitud los eliminamos)\n",
    "lista_listas=[\n",
    "    \"listado_base_Train\",\n",
    "    \"listado_base_Test\",\n",
    "    \"listado_base_Val\"\n",
    "]\n",
    "\n",
    "lista_filtros=[\n",
    "    \"Latitud\",\n",
    "    \"Longitud\"\n",
    "]\n",
    "\n",
    "for element in lista_listas:\n",
    "    if((element in globals()) & (element is not None)):\n",
    "        print(\"Se ha encontrado la lista: \"+str(element))\n",
    "        if (globals()['%s' % element] is None):\n",
    "            print(\"El elemento estaba vacio, así que pasamos a borrarlo\")\n",
    "            del (globals()['%s' % element])\n",
    "        else:\n",
    "            print(\"La lista está formada por \" +str(len(globals()['%s' % element]))+ \" APs. Mostramos las primeras 10 filas de la lista:\\n\" +str(globals()['%s' % element][0:10]))\n",
    "            str_info = str_info + \"Se ha encontrado la lista: \"+str(element) + \" formada por \" +str(len(globals()['%s' % element]))+ \" APs. Mostramos las primeras 10 filas de la lista:\\n\" +str(globals()['%s' % element][0:10]) +\"\\n\"\n",
    "            \n",
    "            #Revisamos que no haya columnas \"Latitud\" o \"Longitud\"\n",
    "            for filtro in lista_filtros:     \n",
    "                if(filtro in globals()[\"%s\"%element]):\n",
    "                    #print(\"Encontrada columna \"+filtro+\" en \" + element + \". Procedemos a borrarla.\")\n",
    "                    posicion = np.where(globals()[\"%s\"%element]==filtro)[0][0]\n",
    "                    #print(posicion)\n",
    "                    globals()[\"%s\"%element]=np.delete(globals()[\"%s\"%element], posicion)\n",
    "                    print(\"En la lista original se encontraron columnas que sobran ('Latitud o Longitud'), tras borrarlas nos quedamos con una lista base de tamaño \"+ str(len(globals()[\"%s\"%element])))\n",
    "                    str_info = str_info + \"En la lista original se encontraron columnas que sobran ('Latitud o Longitud'), tras borrarlas nos quedamos con una lista base de tamaño \"+ str(len(globals()[\"%s\"%element]))\n",
    "                    \n",
    "if(\"matriz_Train\" in globals()):\n",
    "    if(\"listado_base_Train\" not in globals()):\n",
    "        #Filtramos en función de las direcciones MAC, las cuales se presentan en la 3 columna\n",
    "        matriz_Aps = np.zeros(matriz_Train.shape[0])\n",
    "        matriz_Aps = matriz_Train[:,2]\n",
    "\n",
    "        #Nos quedamos solo con uno de cada para crear la lista\n",
    "        Aps_unicos = np.unique(matriz_Aps)\n",
    "        print(\"Entre los datos de entrenamiento se han encontrado un total de \"+ str(len(Aps_unicos))+\" direcciones MAC diferentes. \\nAquí te muestro las 10 primeras:\\n\"+ str(Aps_unicos[0:10]) )\n",
    "        listado_base_Train = Aps_unicos\n",
    "        \n",
    "        str_info = str_info + \"Hemos procesado los datos de entrenamiento. En total hemos detectado \" +str(len(Aps_unicos))+\" direcciones MAC únicas.\" + \"Aquí te muestro las 10 primeras:\\n\"+ str(Aps_unicos[0:10]) + \"\\n\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bf62191",
   "metadata": {},
   "source": [
    "### Funciónes para ordenar los datos\n",
    "Las siguientes funciones sirven para organizar los datos y crear las matrices finales con las que trabajaremos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f80630d",
   "metadata": {},
   "source": [
    "En el caso de la matriz de entrenamiento esta recibe como parámetros:\n",
    "* Identificadores: Una array con las direcciones MAC únicas filtradas anteriormente\n",
    "* Matriz_scan: La matriz en la que aparecen los datos leidos de los csv creada anteriormente\n",
    "* Etiquetas_juntas (opcional): En caso de que este parámetro sea verdadero las etiquetas se incluirán en la matriz final, de lo contrario se crearán dos matrices separadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61f6b6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Organizador_entrenamiento(matriz_scan, secuencias, identificadores, etiquetas_juntas=False):\n",
    "    #En la primera columna de la matriz se almacena el número de escaneo, así que para saber cuantos escaneos hay leemos el valor de la primera columna de la última fila\n",
    "    numero_scaneos=sum(secuencias)+len(secuencias) #Como empiezan en 0 sumamos 1 por cada secuencia\n",
    "    print(\"Localizados \"+str(numero_scaneos)+\" escaneos distintos\")\n",
    "    globals()[\"str_info\"]=globals()[\"str_info\"] + \"Localizados \"+str(numero_scaneos)+\" escaneos distintos.\\n\"\n",
    "    \n",
    "    #Definimos el tamaño de la matriz con los APs\n",
    "    matriz_salida=np.ones((numero_scaneos,len(identificadores)))*(-200)\n",
    "    #Definimos el tamaño de la matriz de etiquetas\n",
    "    matriz_etiquetas=np.zeros((numero_scaneos,2))\n",
    "    \n",
    "    set_datos = 0\n",
    "    offset = 0\n",
    "    muestra_anterior = 0\n",
    "    \n",
    "    #Colocamos los datos de forma ordenada según aparezcan en la lista de identificadores\n",
    "    for ciclo, element in enumerate(matriz_scan):\n",
    "        #Nos aseguramos que la dirección MAC este en la lista, si no algo ha fallado\n",
    "        assert element[2] in identificadores.tolist(), \"La dirección MAC \"+str(element[2])+\" del elemento \"+str(ciclo)+\" no se había listado.\"\n",
    "        \n",
    "        if((int(element[0])!=int(muestra_anterior)) & (int(muestra_anterior) ==secuencias[set_datos])):\n",
    "            offset = secuencias[set_datos] +1\n",
    "            set_datos=set_datos+1\n",
    "            \n",
    "        \n",
    "        fila = offset + int(element[0])\n",
    "        #print(fila, offset, int(element[0]),secuencias[set_datos])\n",
    "        columna = np.where(identificadores == element[2])\n",
    "        \n",
    "        matriz_salida[fila,int(columna[0])] = element[3]\n",
    "        matriz_etiquetas[fila] = [float(s) for s in re.findall(r'-?\\d+\\.?\\d*', str(element[5]))]\n",
    "        \n",
    "        muestra_anterior = element[0]\n",
    "        #print(\"Fila: \"+str(fila)+\" columna: \"+str(columna))\n",
    "    \n",
    "    listado = identificadores\n",
    "    #Si está indicado que se añadan las etiquetas\n",
    "    if(etiquetas_juntas == True):\n",
    "        matriz_salida = np.concatenate((matriz_salida, matriz_etiquetas), axis=1)\n",
    "        matriz_etiquetas = None\n",
    "        listado = np.concatenate((listado, [\"Latitud\",\"Longitud\"]), axis=0)\n",
    "    \n",
    "    return (matriz_salida, matriz_etiquetas, listado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc6b96ab",
   "metadata": {},
   "source": [
    "En el caso del testeo y validación existen varias posibilidades:\n",
    "* En caso de que se le introduzca una lista de APs (por ejemplo la del entrenamiento) los datos se acomodarán a la misma, dejando a elección del usuario si borrar los APs que no aparezcan en la lista o si añadirlos al final.\n",
    "* Si no se introduce una lista base se procesará la misma y e acomodarán los datos.\n",
    "En lo que respecta a las etiquetas lo gestionamos al igual que en el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f6882db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Organizador_general(matriz_scan, secuencias, identificadores=None,  etiquetas_juntas=False):\n",
    "    #En la primera columna de la matriz se almacena el número de escaneo, así que para saber cuantos escaneos hay leemos el valor de la primera columna de la última fila\n",
    "    numero_scaneos=sum(secuencias)+len(secuencias) #Como empiezan en 0 sumamos 1 por cada secuencia\n",
    "    print(\"Localizados \"+str(numero_scaneos)+\" escaneos distintos\")\n",
    "    globals()[\"str_info\"]=globals()[\"str_info\"] + \"Localizados \"+str(numero_scaneos)+\" escaneos distintos.\\n\"\n",
    "    \n",
    "    cuenta=0\n",
    "    set_datos = 0\n",
    "    offset = 0\n",
    "    muestra_anterior = 0\n",
    "    \n",
    "    #Si se ha introducido una lista de etiquetas debemos seguirla\n",
    "    if identificadores is not None:\n",
    "        lista_Aps = identificadores\n",
    "        print(\"La lista con los APs original era de tamaño \"+str(len(lista_Aps)))\n",
    "        \n",
    "        #Comprobamos si la direccion MAC pertenece al listado, y de no ser así la añadimos al final\n",
    "        for element in matriz_scan:\n",
    "            if(element[2] not in lista_Aps.tolist()):\n",
    "                lista_Aps = np.append(lista_Aps, element[2])\n",
    "                cuenta=cuenta+1\n",
    "                #print(\"La señal: \"+str(element)+\" no pertenece al listado\")\n",
    "        print(\"Tras revisar los datos de entrada se han encontrado \"+str(cuenta)+\" APs nuevos, por lo que finalmente se han listado \"+str(len(lista_Aps))+\" Aps.\")\n",
    "        globals()[\"str_info\"]=globals()[\"str_info\"] + \"[Importante]: La lista con los APs original era de tamaño \"+str(len(identificadores))+ \". Tras revisar los datos de entrada se han encontrado \"+str(cuenta)+\" APs nuevos, por lo que finalmente se han listado \"+str(len(lista_Aps))+\" Aps.\\n\"\n",
    "        \n",
    "        #Definimos el tamaño de la matriz con los APs\n",
    "        matriz_salida=np.ones((numero_scaneos,len(lista_Aps)))*(-200)\n",
    "        #Si hay etiquetas definimos el tamaño de la matriz de etiquetas\n",
    "        matriz_etiquetas=np.zeros((numero_scaneos,2))\n",
    "\n",
    "    #Si no se introduce una lista para organizar los AP creamos una propia\n",
    "    else:\n",
    "        #Creamos la lista de los diferentes APs\n",
    "        Aps_unicos = np.zeros(matriz_scan.shape[0])\n",
    "        Aps_unicos = matriz_scan[:,2]\n",
    "        lista_Aps = np.unique(Aps_unicos)\n",
    "        print(\"No se ha introducido ninguna lista, por lo que se procede a organizar los APs conforme aparecen en los csv.\\nEn total se han encontrado \"+ str(len(Aps_unicos))+\" direcciones MAC diferentes. Aquí te muestro las 10 primeras:\\n\"+ str(Aps_unicos[0:10]) )\n",
    "        globals()[\"str_info\"]=globals()[\"str_info\"] + \"No se ha introducido ninguna lista, por lo que se procede a organizar los APs conforme aparecen en los csv.\\nEn total se han encontrado \"+ str(len(Aps_unicos))+\" direcciones MAC diferentes. Aquí te muestro las 10 primeras:\\n\"+ str(Aps_unicos[0:10])+\"\\n\"\n",
    "        \n",
    "        #Definimos el tamaño de la matriz con los APs\n",
    "        matriz_salida=np.ones((numero_scaneos,len(lista_Aps)))*(-200)\n",
    "        #Definimos el tamaño de la matriz de etiquetas\n",
    "        matriz_etiquetas=np.zeros((numero_scaneos,2))\n",
    "        \n",
    "    #Colocamos los datos de forma ordenada según aparezcan en la lista de identificadores\n",
    "    for ciclo, element in enumerate(matriz_scan):\n",
    "        #Nos aseguramos que la dirección MAC este en la lista, si no algo ha fallado\n",
    "        assert element[2] in lista_Aps.tolist(), \"La dirección MAC \"+str(element[2])+\" del elemento \"+str(ciclo)+\" no se había listado.\"\n",
    "\n",
    "        if((int(element[0])!=int(muestra_anterior)) & (int(muestra_anterior) ==secuencias[set_datos])):\n",
    "            offset = secuencias[set_datos] +1\n",
    "            set_datos=set_datos+1\n",
    "\n",
    "        fila = offset + int(element[0])\n",
    "        #print(fila, offset, int(element[0]),secuencias[set_datos])\n",
    "        columna = np.where(lista_Aps == element[2])\n",
    "        #print(columna[0], element[2])\n",
    "        matriz_salida[fila,int(columna[0])] = element[3]\n",
    "\n",
    "        #Si hay etiquetas\n",
    "        if(len(element) >= 5):\n",
    "            if(element[5][2]==\".\"):\n",
    "                matriz_etiquetas[int(element[0])] = [float(s) for s in re.findall(r'-?\\d+\\.?\\d*', str(element[5]))]\n",
    "                hay_etiquetas = True       \n",
    "\n",
    "    #Si está indicado que se añadan las etiquetas\n",
    "    if(etiquetas_juntas == True & (\"hay_etiquetas\" in locals())):\n",
    "        matriz_salida = np.concatenate((matriz_salida, matriz_etiquetas), axis=1)\n",
    "        matriz_etiquetas = None\n",
    "\n",
    "    #Devolvemos el listado\n",
    "    listado = lista_Aps\n",
    "    \n",
    "    return (matriz_salida, matriz_etiquetas, listado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac363e91",
   "metadata": {},
   "source": [
    "### Obtención de las matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b05a6007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mTrain\u001b[0m\n",
      "Localizados 264 escaneos distintos\n",
      "Resultado de tamaño 264x463.\n",
      " Aquí un ejemplo de las primeras 10 filas y columnas:\n",
      "[[-200. -200. -200. -200. -200. -200. -200. -200. -200. -200.]\n",
      " [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200.]\n",
      " [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200.]\n",
      " [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200.]\n",
      " [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200.]\n",
      " [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200.]\n",
      " [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200.]\n",
      " [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200.]\n",
      " [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200.]\n",
      " [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200.]]\n",
      "\u001b[1mTest\u001b[0m\n",
      "Matriz obtenida a partir de una lista base.\n",
      "Localizados 108 escaneos distintos\n",
      "La lista con los APs original era de tamaño 463\n",
      "Tras revisar los datos de entrada se han encontrado 30 APs nuevos, por lo que finalmente se han listado 493 Aps.\n",
      "Resultado de tamaño 108x493.\n",
      " Aquí un ejemplo de las primeras 10 filas y columnas:\n",
      "[[-200. -200. -200. -200. -200. -200. -200. -200. -200. -200.]\n",
      " [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200.]\n",
      " [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200.]\n",
      " [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200.]\n",
      " [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200.]\n",
      " [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200.]\n",
      " [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200.]\n",
      " [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200.]\n",
      " [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200.]\n",
      " [-200. -200. -200. -200. -200. -200. -200. -200. -200. -200.]]\n"
     ]
    }
   ],
   "source": [
    "lista_procesar=[\n",
    "    \"matriz_Train\",\n",
    "    \"matriz_Test\",\n",
    "    \"matriz_Val\"\n",
    "]\n",
    "\n",
    "#Definimos si queremos las etiquetas en la misma matriz que los datos o por separado\n",
    "junto_Train = False\n",
    "junto_Test = False\n",
    "junto_Val = False\n",
    "\n",
    "#Vamos procesando las matrices de una en una\n",
    "for element in lista_procesar:\n",
    "    if element in globals():\n",
    "        print(\"\\033[1m\" + str(element[7:])+ \"\\033[0m\")\n",
    "        str_info = str_info + str(element[7:]) +\"\\n\"\n",
    "        \n",
    "        #Si se trata del conjunto de entrenamiento sabemos que siempre tendremos una lista\n",
    "        if(\"Train\" in element):\n",
    "            globals()[\"matriz_\"+'%s'%element[7:]+\"_organizada\"], globals()[\"matriz_\"+'%s'%element[7:]+\"_etiquetas\"], globals()[\"listado_\"+'%s'%element[7:]] = Organizador_entrenamiento(globals()['%s'%element], globals()[\"secuencias_\"+'%s'%element[7:]], globals()[\"listado_base_\"+'%s'%element[7:]], etiquetas_juntas = globals()[\"junto_\"+'%s'%element[7:]])\n",
    "        \n",
    "        #Si es el conjunto de testeo o validacion puede haber varios escenarios\n",
    "        else:\n",
    "            #Si tenemos una lista base le damos prioridad\n",
    "            if(\"listado_base_\"+ str(element[7:]) in globals()):\n",
    "                print(\"Matriz obtenida a partir de una lista base.\")\n",
    "                str_info = str_info + \"Matriz obtenida a partir de una lista base.\\n\"\n",
    "                globals()[\"matriz_\"+'%s'%element[7:]+\"_organizada\"], globals()[\"matriz_\"+'%s'%element[7:]+\"_etiquetas\"], globals()[\"listado_\"+'%s'%element[7:]] = Organizador_general(globals()['%s'%element], globals()[\"secuencias_\"+'%s'%element[7:]], globals()[\"listado_base_\"+'%s'%element[7:]], etiquetas_juntas = globals()[\"junto_\"+'%s'%element[7:]])\n",
    "            \n",
    "            #Si no tenemos lista base pero tenemos datos de entrenamiento lo lógico será que organizemos los datos siguiendo dicha lista    \n",
    "            elif(\"matriz_Train\" in globals()):\n",
    "                print(\"Matriz obtenida a partir de los datos de entrenamiento. Los AP's específicos de esta parte se encuentran al final\")\n",
    "                str_info = str_info + \"Matriz obtenida a partir de los datos de entrenamiento. Los AP's específicos de esta parte se encuentran al final.\\n\"\n",
    "                globals()[\"matriz_\"+'%s'%element[7:]+\"_organizada\"], globals()[\"matriz_\"+'%s'%element[7:]+\"_etiquetas\"], globals()[\"listado_\"+'%s'%element[7:]] = Organizador_general(globals()['%s'%element], globals()[\"secuencias_\"+'%s'%element[7:]], listado_base_Train, etiquetas_juntas = globals()[\"junto_\"+'%s'%element[7:]])\n",
    "            \n",
    "            #Si no estamos en ninguno de los casos anteriores no indicamos ningún orden\n",
    "            else:\n",
    "                print(\"Matriz obtenida a partir de los datos crudos sin ninguna referencia.\")\n",
    "                str_info = str_info + \"Matriz obtenida a partir de los datos crudos sin ninguna referencia.\\n\"\n",
    "                globals()[\"matriz_\"+'%s'%element[7:]+\"_organizada\"], globals()[\"matriz_\"+'%s'%element[7:]+\"_etiquetas\"], globals()[\"listado_\"+'%s'%element[7:]] = Organizador_general(globals()['%s'%element], globals()[\"secuencias_\"+'%s'%element[7:]], etiquetas_juntas = globals()[\"junto_\"+'%s'%element[7:]])\n",
    "        \n",
    "        print(\"Resultado de tamaño \"+str(globals()[\"matriz_\"+'%s'%element[7:]+\"_organizada\"].shape[0])+ \"x\" +str(globals()[\"matriz_\"+'%s'%element[7:]+\"_organizada\"].shape[1])+\".\\n Aquí un ejemplo de las primeras 10 filas y columnas:\\n\"+ str(globals()[\"matriz_\"+'%s'%element[7:]+\"_organizada\"][:10,:10]))\n",
    "        str_info = str_info + \"Resultado de tamaño \"+str(globals()[\"matriz_\"+'%s'%element[7:]+\"_organizada\"].shape[0])+ \"x\" +str(globals()[\"matriz_\"+'%s'%element[7:]+\"_organizada\"].shape[1])+\".\\n Aquí un ejemplo de las primeras 10 filas y columnas:\\n\"+ str(globals()[\"matriz_\"+'%s'%element[7:]+\"_organizada\"][:10,:10]) + \"\\n\"\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d98851",
   "metadata": {},
   "source": [
    "## Escritura de los datos procesados\n",
    "\n",
    "Finalmente, una vez todos los datos han sido procesados los volvemos a meter a un archivo .csv que localizaremos en la carpeta \"Processed_data\". Dentro de dicha carpeta creamos otra con la fecha actual, sobre la cual crearemos distintas carpetas con el nombre de la hora en la que se ha guardado información."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1ff19df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finalmente creamos creamos las carpetas donde guardarán los datos\n",
    "if(os.path.exists(date_path)!=True):\n",
    "    os.mkdir(date_path)\n",
    "    \n",
    "#Dentro de dicha carpeta creamos otra con la hora en la cual guardaremos los resultados\n",
    "os.mkdir(hour_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "64db295c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secuencias_Train\n",
      "secuencias_Test\n",
      "264 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128]\n",
      "108 [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107]\n"
     ]
    }
   ],
   "source": [
    "#Creacion de los indices de las filas\n",
    "#print(secuencias_Train)\n",
    "lista_indices=[\n",
    "    \"index_Train\",\n",
    "    \"index_Test\",\n",
    "    \"index_Val\"\n",
    "]\n",
    "\n",
    "for indice in lista_indices:\n",
    "    \n",
    "    if(\"secuencias_\"+indice[6:] in globals()):\n",
    "        print(\"secuencias_\"+indice[6:])\n",
    "        globals()[\"index_\"+str(indice[6:])]=[]\n",
    "\n",
    "        for secuencia in globals()[\"secuencias_\"+indice[6:]]:\n",
    "            globals()[\"index_\"+str(indice[6:])] = globals()[\"index_\"+str(indice[6:])] + list(range(secuencia+1))\n",
    "\n",
    "    \n",
    "#print(len(index_Train), index_Train)\n",
    "#print(len(index_Test), index_Test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05bad4bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matriz_Train_organizada guardada en /home/laura/Adrian/Procesaor_dataset/Database/Processed_data/14_9_2022/15:56:58/matriz_Train_organizada.csv\n",
      "matriz_Train_etiquetas guardada en /home/laura/Adrian/Procesaor_dataset/Database/Processed_data/14_9_2022/15:56:58/matriz_Train_etiquetas.csv\n",
      "matriz_Test_organizada guardada en /home/laura/Adrian/Procesaor_dataset/Database/Processed_data/14_9_2022/15:56:58/matriz_Test_organizada.csv\n",
      "matriz_Test_etiquetas guardada en /home/laura/Adrian/Procesaor_dataset/Database/Processed_data/14_9_2022/15:56:58/matriz_Test_etiquetas.csv\n",
      "listado_Train guardada en /home/laura/Adrian/Procesaor_dataset/Database/Processed_data/14_9_2022/15:56:58/listado_Train.csv\n",
      "listado_Test guardada en /home/laura/Adrian/Procesaor_dataset/Database/Processed_data/14_9_2022/15:56:58/listado_Test.csv\n"
     ]
    }
   ],
   "source": [
    "#Pasamos cada matriz a csv y las guardamos en la carpeta.\n",
    "lista_matrices =[\n",
    "    \"matriz_Train_organizada\",\n",
    "    \"matriz_Train_etiquetas\",\n",
    "    \"matriz_Test_organizada\",\n",
    "    \"matriz_Test_etiquetas\",\n",
    "    \"matriz_Val_organizada\",\n",
    "    \"matriz_Val_etiquetas\",\n",
    "    \"listado_Train\",\n",
    "    \"listado_Test\",\n",
    "    \"listado_Val\"\n",
    "]\n",
    "\n",
    "for matriz in lista_matrices:    \n",
    "    #Comprobamos si la matriz existe\n",
    "    if (matriz in globals()):\n",
    "        #Si existe comprobamos si no está vacía\n",
    "        if(globals()['%s' % matriz] is not None):\n",
    "            file_path = hour_path + \"/\" + matriz + \".csv\"\n",
    "            \n",
    "            if(matriz[:7] == \"listado\"):\n",
    "                #index = globals()[\"index_\"+matriz[8:]]\n",
    "                #print(index)\n",
    "                (pd.DataFrame(globals()['%s' % matriz])).to_csv(file_path, index=False, header=False)\n",
    "            \n",
    "            elif(matriz[-16:]==\"Train_organizada\"):\n",
    "                (pd.DataFrame(globals()['%s' % matriz], index = index_Train, columns= listado_Train)).to_csv(file_path)\n",
    "            \n",
    "            elif(\"etiquetas\" in matriz):\n",
    "                if (\"Train\" in matriz):\n",
    "                    ind = index_Train\n",
    "                elif(\"Test\" in matriz):\n",
    "                    ind = index_Test\n",
    "                elif(\"Val\" in matriz):\n",
    "                    ind = index_Val\n",
    "                else:\n",
    "                    ind=False\n",
    "                (pd.DataFrame(globals()['%s' % matriz],index = ind, columns = [\"Latitud\", \"Longitud\"])).to_csv(file_path)\n",
    "            \n",
    "            elif(\"Test_organizada\" in matriz):\n",
    "                (pd.DataFrame(globals()['%s' % matriz], index = index_Test, columns= listado_Test)).to_csv(file_path)\n",
    "            \n",
    "            elif(\"Val_organizada\" in matriz):\n",
    "                (pd.DataFrame(globals()['%s' % matriz], index = index_Val, columns= listado_Val)).to_csv(file_path)\n",
    "            \n",
    "            else:\n",
    "                (pd.DataFrame(globals()['%s' % matriz])).to_csv(file_path, index=False)\n",
    "\n",
    "            #(pd.DataFrame(globals()['%s' % matriz])).to_csv(file_path, index=False)\n",
    "            print(str(matriz) + \" guardada en \" +file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "917ae059",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264\n"
     ]
    }
   ],
   "source": [
    "matriz=\"listado_Train\"\n",
    "\n",
    "index = globals()[\"index_\"+matriz[8:]]\n",
    "print(len(index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b90759f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳0:0:1\n"
     ]
    }
   ],
   "source": [
    "#Recuento del tiempo\n",
    "tiempo_fin = time.time()\n",
    "tiempo_total = tiempo_fin-tiempo_inicio\n",
    "\n",
    "segundos=tiempo_total\n",
    " \n",
    "horas=int(segundos/3600)\n",
    "segundos-=horas*3600\n",
    "minutos=int(segundos/60)\n",
    "segundos-=int(minutos*60)\n",
    "segundos =int(segundos)\n",
    "\n",
    "print(\"\\u23F3%s:%s:%s\" % (horas,minutos,segundos))\n",
    "str_info = str_info + \"\\u23F3 En total el programa ha tardado \" + str(horas) +\":\"+str(minutos)+\":\"+str(segundos)+\".\\n\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "29a914e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1mPrograma finalizado con éxito\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#Escribimos el .txt\n",
    "informacion = open(hour_path + \"/informacion.txt\", \"w\")\n",
    "informacion.write(str_info)\n",
    "informacion.close()\n",
    "\n",
    "#Acabamos el programa\n",
    "print(\"\\033[1mPrograma finalizado con éxito\\033[0m\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
